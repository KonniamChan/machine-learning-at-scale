{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS W261: Machine Learning at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konniam Chan  \n",
    "Time of submission: 12:30am PST   \n",
    "W261-3 Spring 2016    \n",
    "Week 2: Homework  \n",
    "January 26, 2016  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.0.  \n",
    "What is a race condition in the context of parallel computation? Give an example.\n",
    "What is MapReduce?\n",
    "How does it differ from Hadoop?\n",
    "Which programming paradigm is Hadoop based on? Explain and give a simple example in code and show the code running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Race condition could manifest itself as a bug in a parallel program without synchronization. The final value of the operation depends on operation order. For instance, if both A and B were to perform an operation X = X + 1, on the same variable. Depending on which gets done first, the result could be X + 1 or X + 2.\n",
    "- MapReduce is a parallel programming paradigm that enables distributed processing of data sets on commodity nodes. Hadoop is a set of open-source projects that facilitate parallel computing, including MapReduce, HDFS, Avro, Hive, and other utilities.\n",
    "- Hadoop utilizes MapReduce for processing, which resembles functional programming closely. Functional programming treats computations as functions, and avoids saving states whenever possible. MapReduce closely approximates the map and reduce functions in that regime. Examine sample code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mapper that computes x-square:\n",
      "[1, 4, 9, 16, 25]\n",
      "Sample reducer sums all elements:\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Mapper\n",
    "input = [1,2,3,4,5]\n",
    "# Compute x^2 using map\n",
    "print \"Sample mapper that computes x-square:\"\n",
    "print map(lambda x: x**2, input)\n",
    "\n",
    "# Reducer\n",
    "print \"Sample reducer sums all elements:\"\n",
    "print reduce(lambda x,y: x+y, input)\n",
    "\n",
    "# Note: both mapper and reducer take another function, and use that function to transform the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.1. Sort in Hadoop MapReduce\n",
    "Given as input: Records of the form `<integer, “NA”>`, where integer is any integer, and “NA” is just the empty string.\n",
    "Output: sorted key value pairs of the form `<integer, “NA”>` in decreasing order; what happens if you have multiple reducers? Do you need additional steps? Explain.\n",
    "\n",
    "Write code to generate N  random records of the form `<integer, “NA”>`. Let N = 10,000.\n",
    "Write the python Hadoop streaming map-reduce job to perform this sort. Display the top 10 biggest numbers. Display the 10 smallest numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting yarn daemons\n",
      "starting resourcemanager, logging to /Users/InfernoIX/hadoop-2.7.1/logs/yarn-InfernoIX-resourcemanager-Konniams-MacBook-Air.local.out\n",
      "localhost: starting nodemanager, logging to /Users/InfernoIX/hadoop-2.7.1/logs/yarn-InfernoIX-nodemanager-Konniams-MacBook-Air.local.out\n",
      "16/01/23 15:26:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Starting namenodes on [localhost]\n",
      "localhost: starting namenode, logging to /Users/InfernoIX/hadoop-2.7.1/logs/hadoop-InfernoIX-namenode-Konniams-MacBook-Air.local.out\n",
      "localhost: starting datanode, logging to /Users/InfernoIX/hadoop-2.7.1/logs/hadoop-InfernoIX-datanode-Konniams-MacBook-Air.local.out\n",
      "Starting secondary namenodes [0.0.0.0]\n",
      "0.0.0.0: starting secondarynamenode, logging to /Users/InfernoIX/hadoop-2.7.1/logs/hadoop-InfernoIX-secondarynamenode-Konniams-MacBook-Air.local.out\n",
      "16/01/23 15:26:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "## Start HDFS and Yarn\n",
    "!start-yarn.sh\n",
    "!start-dfs.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from __future__ import division\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create input file\n",
    "def hw_2_1():\n",
    "    np.random.seed(0)\n",
    "    # Pick 10,000 numbers from 100,000 and save to txt\n",
    "    N = 10000\n",
    "    # Save\n",
    "    np.savetxt(\"hw_2_1.txt\", np.random.randint(0, 100000, N), fmt='%i,')\n",
    "\n",
    "hw_2_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10000 hw_2_1.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l hw_2_1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68268,\r\n",
      "43567,\r\n",
      "42613,\r\n",
      "45891,\r\n",
      "21243,\r\n",
      "95939,\r\n",
      "97639,\r\n",
      "41993,\r\n",
      "86293,\r\n",
      "55026,\r\n"
     ]
    }
   ],
   "source": [
    "!head hw_2_1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/23 01:10:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "# Put on HDFS\n",
    "!hdfs dfs -put hw_2_1.txt /user/konniam/week_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/mapper.py\n",
    "#!/usr/bin/env python\n",
    "# MapReduce Task to Sort Numbers\n",
    "# The mapper will split the record of the form <integer, \"\"> into <integer \\t>.\n",
    "# This output will get sorted in reverse numerical order.\n",
    "# The reducer doesn't need to do anything, so it could be an IdentityReducer\n",
    "import sys\n",
    "for line in sys.stdin:\n",
    "    # Extract the number\n",
    "    num = line.strip().split(',')[0]\n",
    "    # Output the number\n",
    "    print num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x ~/mapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 23:28:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "packageJobJar: [/var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/hadoop-unjar8474472715611845283/] [] /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/streamjob679131600247708839.jar tmpDir=null\n",
      "16/01/25 23:28:51 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/25 23:28:51 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/25 23:28:52 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/01/25 23:28:53 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/01/25 23:28:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1453765434085_0010\n",
      "16/01/25 23:28:53 INFO impl.YarnClientImpl: Submitted application application_1453765434085_0010\n",
      "16/01/25 23:28:53 INFO mapreduce.Job: The url to track the job: http://Konniams-MacBook-Air.local:8088/proxy/application_1453765434085_0010/\n",
      "16/01/25 23:28:53 INFO mapreduce.Job: Running job: job_1453765434085_0010\n",
      "16/01/25 23:29:04 INFO mapreduce.Job: Job job_1453765434085_0010 running in uber mode : false\n",
      "16/01/25 23:29:04 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/01/25 23:29:17 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "16/01/25 23:29:24 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "16/01/25 23:29:24 INFO mapreduce.Job: Job job_1453765434085_0010 completed successfully\n",
      "16/01/25 23:29:24 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=88889\n",
      "\t\tFILE: Number of bytes written=529572\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=62420\n",
      "\t\tHDFS: Number of bytes written=68883\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=22615\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=4512\n",
      "\t\tTotal time spent by all map tasks (ms)=22615\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4512\n",
      "\t\tTotal vcore-seconds taken by all map tasks=22615\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=4512\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=23157760\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=4620288\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000\n",
      "\t\tMap output records=10000\n",
      "\t\tMap output bytes=68883\n",
      "\t\tMap output materialized bytes=88895\n",
      "\t\tInput split bytes=210\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=9491\n",
      "\t\tReduce shuffle bytes=88895\n",
      "\t\tReduce input records=10000\n",
      "\t\tReduce output records=10000\n",
      "\t\tSpilled Records=20000\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=561\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "\t\tTotal committed heap usage (bytes)=490209280\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=62210\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=68883\n",
      "16/01/25 23:29:24 INFO streaming.StreamJob: Output directory: /user/konniam/week_02/hw_2_1_output\n"
     ]
    }
   ],
   "source": [
    "# Run MapReduce job\n",
    "# The keycomparator options make the sorting come in descending order\n",
    "# Use 1 reducer\n",
    "!hadoop jar hadoop-streaming-2.7.1.jar \\\n",
    "-D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \\\n",
    "-D mapreduce.partition.keycomparator.options=-k1,1nr \\\n",
    "-D mapreduce.job.reduces=1 \\\n",
    "-mapper ~/mapper.py \\\n",
    "-reducer org.apache.hadoop.mapred.lib.IdentityReducer \\\n",
    "-input /user/konniam/week_02/hw_2_1.txt \\\n",
    "-output /user/konniam/week_02/hw_2_1_output \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 23:29:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "99980\t\n",
      "99975\t\n",
      "99965\t\n",
      "99963\t\n",
      "99943\t\n",
      "99938\t\n",
      "99920\t\n",
      "99914\t\n",
      "99913\t\n",
      "99892\t\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "# Display 10 biggest numbers\n",
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_1_output/* | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 23:29:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "102\t\n",
      "100\t\n",
      "95\t\n",
      "93\t\n",
      "75\t\n",
      "43\t\n",
      "30\t\n",
      "21\t\n",
      "13\t\n",
      "10\t\n"
     ]
    }
   ],
   "source": [
    "# Display 10 smallest numbers\n",
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_1_output/* | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Response\n",
    "Here we used one reducer. If we were to use multiple reducers, each reducer will output its own file with sorted numbers. However, unless we sort all the numbers before we partition them for the reducers. We only get a few files with their own sorted list. We would have to sort all the files one more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.2.  WORDCOUNT\n",
    "Using the Enron data from HW1 and Hadoop MapReduce streaming, write the mapper/reducer job that  will determine the word count (number of occurrences) of each white-space delimitted token (assume spaces, fullstops, comma as delimiters). Examine the word “assistance” and report its word count results.\n",
    "\n",
    " \n",
    "CROSSCHECK: >grep assistance enronemail_1h.txt|cut -d$'\\t' -f4| grep assistance|wc -l    \n",
    "       8    \n",
    "NOTE  \"assistance\" occurs on 8 lines but how many times does the token occur? 10 times! This is the number we are looking for!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional)\n",
    "Remove ^A and ^M characters using vi from the training data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/mapper.py\n",
    "#!/usr/bin/env python\n",
    "## mapper.py\n",
    "## Author: Konniam Chan\n",
    "## Description: mapper code for HW2.2\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Regex split objects with specified delimiters (space, period, comma)\n",
    "regex_beg = re.compile(r'^[\\s.,\"]+')\n",
    "regex_end = re.compile(r'[\\s.,\"]+$')\n",
    "regex_split = re.compile(r'[\\s.,]+')\n",
    "# Counter dictionary\n",
    "wordcounts = Counter()\n",
    "\n",
    "# Process each document\n",
    "for line in sys.stdin:\n",
    "    # Lower case\n",
    "    line = line.strip().lower()\n",
    "    # Some lines have missing subjects\n",
    "    if len(line.split(\"\\t\")) == 4:\n",
    "        doc_id, label, subject, body = line.split(\"\\t\")\n",
    "    else:\n",
    "        subject = \"na\"\n",
    "        doc_id, label, body = line.split(\"\\t\")\n",
    "    # Remove delimiters at beginning and end of subjects and body    \n",
    "    subject = regex_beg.sub('', subject)\n",
    "    subject = regex_end.sub('', subject)\n",
    "    body = regex_beg.sub('', body)\n",
    "    body = regex_end.sub('', body)\n",
    "    # Split into words\n",
    "    words = regex_split.split(subject + \" \" + body)\n",
    "    # Sum words that go through each mapper\n",
    "    wordcounts += Counter(words)\n",
    "\n",
    "# Output\n",
    "for word, count in wordcounts.items():\n",
    "    print '%s\\t%s' % (word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/reducer.py\n",
    "#!/usr/bin/env python\n",
    "## reducer.py\n",
    "## Author: Konniam Chan\n",
    "## Description: reducer code for HW2.2\n",
    "import sys\n",
    "current_word = None\n",
    "current_count = 0\n",
    "word = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "    # Obtain word and intermediate counts\n",
    "    line = line.strip()\n",
    "    word, count = line.split('\\t', 1)\n",
    "    count = int(count)\n",
    "    # Rely on sorting to increment word counts\n",
    "    if current_word == word:\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_word:            \n",
    "            print '%s\\t%s' % (current_word, current_count)\n",
    "        current_count = count\n",
    "        current_word = word\n",
    "\n",
    "# Output last word\n",
    "if current_word == word:\n",
    "    print '%s\\t%s' % (current_word, current_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod a+x ~/reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 11:57:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "# Put enron emails onto HDFS\n",
    "!hdfs dfs -put enronemail_1h.txt /user/konniam/week_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 11:58:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "packageJobJar: [/var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/hadoop-unjar2874213692464979909/] [] /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/streamjob1868682628016300695.jar tmpDir=null\n",
      "16/01/24 11:58:06 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 11:58:06 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 11:58:07 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/01/24 11:58:07 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/01/24 11:58:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1453657675452_0002\n",
      "16/01/24 11:58:07 INFO impl.YarnClientImpl: Submitted application application_1453657675452_0002\n",
      "16/01/24 11:58:07 INFO mapreduce.Job: The url to track the job: http://Konniams-MacBook-Air.local:8088/proxy/application_1453657675452_0002/\n",
      "16/01/24 11:58:07 INFO mapreduce.Job: Running job: job_1453657675452_0002\n",
      "16/01/24 11:58:16 INFO mapreduce.Job: Job job_1453657675452_0002 running in uber mode : false\n",
      "16/01/24 11:58:16 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/01/24 11:58:25 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "16/01/24 11:58:33 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "16/01/24 11:58:33 INFO mapreduce.Job: Job job_1453657675452_0002 completed successfully\n",
      "16/01/24 11:58:33 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=94462\n",
      "\t\tFILE: Number of bytes written=541093\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=217192\n",
      "\t\tHDFS: Number of bytes written=64704\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=13746\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=4853\n",
      "\t\tTotal time spent by all map tasks (ms)=13746\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4853\n",
      "\t\tTotal vcore-seconds taken by all map tasks=13746\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=4853\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=14075904\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=4969472\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=100\n",
      "\t\tMap output records=7926\n",
      "\t\tMap output bytes=78604\n",
      "\t\tMap output materialized bytes=94468\n",
      "\t\tInput split bytes=224\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=6374\n",
      "\t\tReduce shuffle bytes=94468\n",
      "\t\tReduce input records=7926\n",
      "\t\tReduce output records=6374\n",
      "\t\tSpilled Records=15852\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=346\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "\t\tTotal committed heap usage (bytes)=492830720\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=216968\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=64704\n",
      "16/01/24 11:58:33 INFO streaming.StreamJob: Output directory: /user/konniam/week_02/hw_2_2_output\n"
     ]
    }
   ],
   "source": [
    "# Run MapReduce job\n",
    "# Specify 1 reducer in this case \n",
    "!hadoop jar hadoop-streaming-2.7.1.jar \\\n",
    "-D mapreduce.job.reduces=1 \\\n",
    "-mapper ~/mapper.py \\\n",
    "-reducer ~/reducer.py \\\n",
    "-input /user/konniam/week_02/enronemail_1h.txt \\\n",
    "-output /user/konniam/week_02/hw_2_2_output \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 12:01:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "assistance\t10\n"
     ]
    }
   ],
   "source": [
    "# Check the word \"assistance\"\n",
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_2_output/* | grep assistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.2.1  \n",
    "Using Hadoop MapReduce and your wordcount job (from HW2.2) determine the top-10 occurring tokens (most frequent tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 12:00:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "the\t1240\n",
      "to\t914\n",
      "and\t659\n",
      "of\t556\n",
      "a\t527\n",
      "in\t415\n",
      "you\t407\n",
      "your\t389\n",
      "for\t369\n",
      "@\t361\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_2_output/* | sort -k2,2nr | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.3. Multinomial NAIVE BAYES with NO Smoothing\n",
    "Using the Enron data from HW1 and Hadoop MapReduce, write  a mapper/reducer job(s) that\n",
    "   will both learn  Naive Bayes classifier and classify the Enron email messages using the learnt Naive Bayes classifier. Use all white-space delimitted tokens as independent input variables (assume spaces, fullstops, commas as delimiters). Note: for multinomial Naive Bayes, the Pr(X=“assistance”|Y=SPAM) is calculated as follows:\n",
    "\n",
    "   the number of times “assistance” occurs in SPAM labeled documents / the number of words in documents labeled SPAM \n",
    "\n",
    "   E.g.,   “assistance” occurs 5 times in all of the documents Labeled SPAM, and the length in terms of the number of words in all documents labeled as SPAM (when concatenated) is 1,000. Then Pr(X=“assistance”|Y=SPAM) = 5/1000. Note this is a multinomial estimation of the class conditional for a Naive Bayes Classifier. No smoothing is needed in this HW. Multiplying lots of probabilities, which are between 0 and 1, can result in floating-point underflow. Since log(xy) = log(x) + log(y), it is better to perform all computations by summing logs of probabilities rather than multiplying probabilities. Please pay attention to probabilites that are zero! They will need special attention. Count up how many times you need to process a zero probabilty for each class and report. \n",
    "\n",
    "   Report the performance of your learnt classifier in terms of misclassifcation error rate of your multinomial Naive Bayes Classifier. Plot a histogram of the log posterior probabilities (i.e., log(Pr(Class|Doc))) for each class over the training set. Summarize what you see. \n",
    "\n",
    "   Error Rate = misclassification rate with respect to a provided set (say training set in this case). It is more formally defined here:\n",
    "\n",
    "Let DF represent the evalution set in the following:\n",
    "Err(Model, DF) = |{(X, c(X)) ∈ DF : c(X) != Model(x)}|   / |DF|\n",
    "\n",
    "Where || denotes set cardinality; c(X) denotes the class of the tuple X in DF; and Model(X) denotes the class inferred by the Model “Model”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Strategy\n",
    "Split this exercise into 2 sets of MR jobs.  \n",
    "**Training Step**  \n",
    "1 - Mapper: (Input docs) -> intermediate (word, spam/ham, count)  \n",
    "1 - Reducer: intermediate (word, spam/ham, count) -> final (word, spam/ham, count)  \n",
    "**Classification Step**  \n",
    "2 - Mapper: (Input docs) -> predicted labels  \n",
    "2 - Reducer: None  \n",
    "(pass in word counts from training step to do classification)  \n",
    "  \n",
    "We will use this same strategy for all MapReduce NB jobs here in this HW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/mapper.py\n",
    "#!/usr/bin/env python\n",
    "## mapper.py\n",
    "## Author: Konniam Chan\n",
    "## Description: mapper code for HW2.3\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "# Map from integer label to word label\n",
    "label_map = {\"1\":\"spam\", \"0\":\"ham\"}\n",
    "# Dictionary to keep track of terms\n",
    "wordcounts = {\"spam\": Counter(), \"ham\": Counter()}\n",
    "# Regex split objects with specified delimiters (space, period, comma)\n",
    "regex_beg = re.compile(r'^[\\s.,\"]+')\n",
    "regex_end = re.compile(r'[\\s.,\"]+$')\n",
    "regex_split = re.compile(r'[\\s.,]+')\n",
    "\n",
    "# Process each document\n",
    "for line in sys.stdin:\n",
    "    # Lower case\n",
    "    line = line.strip().lower()\n",
    "    # Some lines have missing subjects\n",
    "    if len(line.split(\"\\t\")) == 4:\n",
    "        doc_id, label, subject, body = line.split(\"\\t\")\n",
    "    else:\n",
    "        subject = \"na\"\n",
    "        doc_id, label, body = line.split(\"\\t\")\n",
    "    # Remove delimiters at beginning and end of subjects and body\n",
    "    subject = regex_beg.sub('', subject)\n",
    "    subject = regex_end.sub('', subject)\n",
    "    body = regex_beg.sub('', body)\n",
    "    body = regex_end.sub('', body)\n",
    "    # Split into words\n",
    "    words = regex_split.split(subject + \" \" + body)\n",
    "    # Sum words that go through each mapper\n",
    "    label = label_map[label]\n",
    "    wordcounts[label] += Counter(words)\n",
    "    # Increment number of documents\n",
    "    wordcounts[label][\"*numdocs\"] += 1\n",
    "# Output each word\n",
    "for label in wordcounts:\n",
    "    for word in wordcounts[label]:\n",
    "        print '%s\\t%s\\t%s' % (word, label, wordcounts[label][word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/reducer.py\n",
    "#!/usr/bin/env python\n",
    "## reducer.py\n",
    "## Author: Konniam Chan\n",
    "## Description: reducer code for HW2.3\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "# Dictionary to keep track of terms\n",
    "wordcounts = {\"spam\": Counter(), \"ham\": Counter()}\n",
    "# Process each tuple in the form of (word, spam/ham, count) separated by \\t\n",
    "for line in sys.stdin:\n",
    "    word, label, count = line.strip().split(\"\\t\")\n",
    "    wordcounts[label][word] += int(count)\n",
    "\n",
    "# Output each word\n",
    "for label in wordcounts:\n",
    "    for word in wordcounts[label]:\n",
    "        print '%s\\t%s\\t%s' % (word, label, wordcounts[label][word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 12:07:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "packageJobJar: [/var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/hadoop-unjar8048476221407268102/] [] /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/streamjob3395343983938593158.jar tmpDir=null\n",
      "16/01/24 12:07:03 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 12:07:04 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 12:07:05 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/01/24 12:07:05 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/01/24 12:07:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1453657675452_0004\n",
      "16/01/24 12:07:05 INFO impl.YarnClientImpl: Submitted application application_1453657675452_0004\n",
      "16/01/24 12:07:05 INFO mapreduce.Job: The url to track the job: http://Konniams-MacBook-Air.local:8088/proxy/application_1453657675452_0004/\n",
      "16/01/24 12:07:05 INFO mapreduce.Job: Running job: job_1453657675452_0004\n",
      "16/01/24 12:07:13 INFO mapreduce.Job: Job job_1453657675452_0004 running in uber mode : false\n",
      "16/01/24 12:07:13 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/01/24 12:07:23 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "16/01/24 12:07:30 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "16/01/24 12:07:31 INFO mapreduce.Job: Job job_1453657675452_0004 completed successfully\n",
      "16/01/24 12:07:31 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=147362\n",
      "\t\tFILE: Number of bytes written=646893\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=217192\n",
      "\t\tHDFS: Number of bytes written=107220\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=14192\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=4674\n",
      "\t\tTotal time spent by all map tasks (ms)=14192\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4674\n",
      "\t\tTotal vcore-seconds taken by all map tasks=14192\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=4674\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=14532608\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=4786176\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=100\n",
      "\t\tMap output records=9056\n",
      "\t\tMap output bytes=129244\n",
      "\t\tMap output materialized bytes=147368\n",
      "\t\tInput split bytes=224\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=6375\n",
      "\t\tReduce shuffle bytes=147368\n",
      "\t\tReduce input records=9056\n",
      "\t\tReduce output records=7390\n",
      "\t\tSpilled Records=18112\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=271\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "\t\tTotal committed heap usage (bytes)=502792192\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=216968\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=107220\n",
      "16/01/24 12:07:31 INFO streaming.StreamJob: Output directory: /user/konniam/week_02/hw_2_3_output\n"
     ]
    }
   ],
   "source": [
    "# Run MapReduce job\n",
    "# Specify 1 reducer\n",
    "!hadoop jar hadoop-streaming-2.7.1.jar \\\n",
    "-D mapreduce.job.reduces=1 \\\n",
    "-mapper ~/mapper.py \\\n",
    "-reducer ~/reducer.py \\\n",
    "-input /user/konniam/week_02/enronemail_1h.txt \\\n",
    "-output /user/konniam/week_02/hw_2_3_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 15:43:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "!!\tspam\t1\n",
      "\"\"\tham\t83\n",
      "\"\"\tspam\t174\n",
      "\"\"'bcli\tham\t1\n",
      "\"\"'benewm\tham\t1\n",
      "\"\"'bjeffrie\tham\t1\n",
      "\"\"'blong\tham\t1\n",
      "\"\"'bredd\tham\t1\n",
      "\"\"'celias\tham\t1\n",
      "\"\"'cenochs\tham\t1\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_3_output/part* | sort -k1,1 | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Classification\n",
    "The above MR job trained the model by obtaining the counts of all terms in either spam or ham.  \n",
    "We can now pass the result file from above when we want to classify our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/mapper_classify.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/mapper_classify.py\n",
    "#!/usr/bin/env python\n",
    "## mapper_classify.py\n",
    "## Author: Konniam Chan\n",
    "## Description: classification mapper code for HW2.3\n",
    "from __future__ import division\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "\n",
    "# Map from integer label to word label\n",
    "label_map = {\"1\":\"spam\", \"0\":\"ham\"}\n",
    "# Regex split objects with specified delimiters (space, period, comma)\n",
    "regex_beg = re.compile(r'^[\\s.,\"]+')\n",
    "regex_end = re.compile(r'[\\s.,\"]+$')\n",
    "regex_split = re.compile(r'[\\s.,]+')\n",
    "\n",
    "# Load trained Naive Bayes model in memory\n",
    "wordcounts = {\"spam\": {}, \"ham\": {}}\n",
    "with open(\"wordcounts_2_3.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        word, label, count = line.strip().split(\"\\t\")\n",
    "        wordcounts[label][word] = int(count)\n",
    "# Calculate total number of terms\n",
    "terms_spam = sum(wordcounts['spam'].values())\n",
    "terms_ham = sum(wordcounts['ham'].values())\n",
    "# Calculate priors\n",
    "prior_spam = wordcounts['spam']['*numdocs'] / (wordcounts['spam']['*numdocs'] + wordcounts['ham']['*numdocs'])\n",
    "prior_ham = 1 - prior_spam\n",
    "\n",
    "# Process each document\n",
    "for line in sys.stdin:\n",
    "    line = line.strip().lower()\n",
    "    # Some lines have missing subjects\n",
    "    if len(line.split(\"\\t\")) == 4:\n",
    "        doc_id, label, subject, body = line.split(\"\\t\")\n",
    "    else:\n",
    "        subject = \"na\"\n",
    "        doc_id, label, body = line.split(\"\\t\")\n",
    "    # Remove delimiters at beginning and end of subjects and body\n",
    "    subject = regex_beg.sub('', subject)\n",
    "    subject = regex_end.sub('', subject)\n",
    "    body = regex_beg.sub('', body)\n",
    "    body = regex_end.sub('', body)\n",
    "    # Split into words\n",
    "    words = regex_split.split(subject + \" \" + body)\n",
    "    \n",
    "    # Initialize probabilities with priors\n",
    "    log_probs = {\"spam\": math.log(prior_spam), \"ham\": math.log(prior_ham)}\n",
    "    # Keep track of number of zero probabilities for each doc\n",
    "    zero_spam, zero_ham = 0, 0\n",
    "    # Iterate through each word and add probabilities\n",
    "    for word in words:\n",
    "        # If word frequency is zero, record it, then skip the term\n",
    "        if word not in wordcounts['spam'] or word not in wordcounts['ham']:\n",
    "            if word not in wordcounts['spam']:\n",
    "                zero_spam += 1\n",
    "            else:\n",
    "                zero_ham += 1\n",
    "            # Skip this term in calculation of probabilities\n",
    "            continue\n",
    "        else:\n",
    "            # Usual definition of NB probabilities\n",
    "            log_probs[\"spam\"] += math.log(wordcounts['spam'][word] / terms_spam)\n",
    "            log_probs[\"ham\"] += math.log(wordcounts['ham'][word] / terms_ham)\n",
    "\n",
    "    # Classify\n",
    "    predicted_label = \"1\" if log_probs[\"spam\"] > log_probs[\"ham\"] else \"0\"\n",
    "    # Normalize probabilities for output, prevent overflow\n",
    "    if log_probs[\"ham\"] - log_probs[\"spam\"] > 700:\n",
    "            probs_spam = 0\n",
    "    else:\n",
    "        probs_spam = 1 / (1 + math.exp(log_probs[\"ham\"] - log_probs[\"spam\"]))\n",
    "    probs_ham = 1 - probs_spam\n",
    "    \n",
    "    # Output (DocID, label, predicted label, p_spam, p_ham, zero_spam, zero_ham)\n",
    "    print '\\t'.join([doc_id, label, predicted_label, \n",
    "                     str(probs_spam), str(probs_ham),\n",
    "                     str(zero_spam), str(zero_ham)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x ~/mapper_classify.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 13:53:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "16/01/24 13:53:08 WARN hdfs.DFSClient: DFSInputStream has been closed already\n"
     ]
    }
   ],
   "source": [
    "# Transfer results from 1st MR job to a local directory\n",
    "!hdfs dfs -get \"/user/konniam/week_02/hw_2_3_output/part-00000\" ~/wordcounts_2_3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 15:04:59 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "16/01/24 15:04:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "packageJobJar: [/Users/InfernoIX/wordcounts_2_3.txt, /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/hadoop-unjar4598644515510618160/] [] /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/streamjob3052404937059671916.jar tmpDir=null\n",
      "16/01/24 15:05:01 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 15:05:01 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 15:05:02 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/01/24 15:05:03 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/01/24 15:05:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1453657675452_0008\n",
      "16/01/24 15:05:03 INFO impl.YarnClientImpl: Submitted application application_1453657675452_0008\n",
      "16/01/24 15:05:03 INFO mapreduce.Job: The url to track the job: http://Konniams-MacBook-Air.local:8088/proxy/application_1453657675452_0008/\n",
      "16/01/24 15:05:03 INFO mapreduce.Job: Running job: job_1453657675452_0008\n",
      "16/01/24 15:05:14 INFO mapreduce.Job: Job job_1453657675452_0008 running in uber mode : false\n",
      "16/01/24 15:05:14 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/01/24 15:05:24 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "16/01/24 15:05:25 INFO mapreduce.Job: Job job_1453657675452_0008 completed successfully\n",
      "16/01/24 15:05:25 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=236380\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=217192\n",
      "\t\tHDFS: Number of bytes written=5600\n",
      "\t\tHDFS: Number of read operations=10\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17437\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=17437\n",
      "\t\tTotal vcore-seconds taken by all map tasks=17437\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=17855488\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=100\n",
      "\t\tMap output records=100\n",
      "\t\tInput split bytes=224\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=258\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "\t\tTotal committed heap usage (bytes)=186646528\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=216968\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=5600\n",
      "16/01/24 15:05:25 INFO streaming.StreamJob: Output directory: /user/konniam/week_02/hw_2_3_output_classify\n"
     ]
    }
   ],
   "source": [
    "# Run MapReduce job\n",
    "# Map-only job. Pass in text file with wordcounts\n",
    "!hadoop jar hadoop-streaming-2.7.1.jar \\\n",
    "-D mapreduce.job.reduces=0 \\\n",
    "-mapper ~/mapper_classify.py \\\n",
    "-input /user/konniam/week_02/enronemail_1h.txt \\\n",
    "-output /user/konniam/week_02/hw_2_3_output_classify \\\n",
    "-file ~/wordcounts_2_3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 15:14:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "0011.2003-12-18.gp\t1\t1\t0.999999989025\t1.09750638577e-08\t0\t37\n",
      "0011.2004-08-01.bg\t1\t1\t0.999999956896\t4.3104383729e-08\t0\t37\n",
      "0012.1999-12-14.farmer\t0\t0\t1.51562851903e-45\t1.0\t142\t0\n",
      "0012.1999-12-14.kaminski\t0\t0\t3.07583767617e-35\t1.0\t62\t0\n",
      "0012.2000-01-17.beck\t0\t0\t4.96321540941e-110\t1.0\t156\t0\n",
      "0012.2000-06-08.lokay\t0\t1\t0.999999997354\t2.64601918154e-09\t31\t0\n",
      "0012.2001-02-09.kitchen\t0\t0\t7.99826839655e-06\t0.999992001732\t20\t0\n",
      "0012.2003-12-19.gp\t1\t1\t0.996915425172\t0.00308457482785\t0\t9\n",
      "0013.1999-12-14.farmer\t0\t0\t3.9936291718e-25\t1.0\t69\t0\n",
      "0013.1999-12-14.kaminski\t0\t0\t3.51968974018e-38\t1.0\t67\t0\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "# Examine output (format: DocID, label, predicted_label, zero_spam, zero_ham)\n",
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_3_output_classify/part* | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Error Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 15:12:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_3_output_classify/part* > hw_2_3_results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words that hit zero probability for class spam: 4932.\n",
      "Number of words that hit zero probability for class ham: 6447.\n",
      "The training error is 0.11.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAALPCAYAAACHTs05AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAMA0CxhGACAZgnDAAA0SxgGAKBZr9rWgWtZhviKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c9f3590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hw_2_3_error():\n",
    "    # Parse results\n",
    "    columns = ['docid', 'label', 'preds', 'probs_spam', 'probs_ham', 'zero_spam', 'zero_ham']\n",
    "    df = pd.read_table(\"hw_2_3_results.txt\", header=None, names=columns)\n",
    "    # Print total number of zero probabilities for each class\n",
    "    print \"Number of words that hit zero probability for class spam: {}.\".format(\n",
    "        sum(df['zero_spam']))\n",
    "    print \"Number of words that hit zero probability for class ham: {}.\".format(\n",
    "        sum(df['zero_ham']))\n",
    "    # Calculate error rate and output\n",
    "    print \"The training error is {}.\".format(np.mean(df['label'] != df['preds']))\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(211)\n",
    "    sns.distplot(df['probs_spam'], bins = 20, kde=None)\n",
    "    plt.subplot(212)\n",
    "    sns.distplot(df['probs_ham'], bins = 20, kde=None)\n",
    "\n",
    "hw_2_3_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error (without smoothing) is 11%, which is pretty bad considering we have over 7000 parameters for 100 data points. 4932 and 6447 terms hit zero probabilities for either spam or ham, and are skipped in the NB calculation both both classes.  \n",
    "  \n",
    "The plots of the probabilities show a very bimodal distribution, with significant density near 0 or 1, showing that NB is usually very confident in its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.4 \n",
    "Repeat HW2.3 with the following modification: use Laplace plus-one smoothing. Compare the misclassifcation error rates for 2.3 versus 2.4 and explain the differences.\n",
    "\n",
    "For a quick reference on the construction of the Multinomial NAIVE BAYES classifier that you will code,\n",
    "please consult the \"Document Classification\" section of the following wikipedia page:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Document_classification\n",
    "\n",
    "OR the original paper by the curators of the Enron email data:\n",
    "\n",
    "http://www.aueb.gr/users/ion/docs/ceas2006_paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Strategy\n",
    "The classifier with Laplace smoothing can use the wordcounts created in the 1st MR job from 2.3. All we have to do is to modify how we calculate how probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/mapper_classify.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/mapper_classify.py\n",
    "#!/usr/bin/env python\n",
    "## mapper_classify.py\n",
    "## Author: Konniam Chan\n",
    "## Description: classification (with Laplace smoothing) mapper code for HW2.4\n",
    "from __future__ import division\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# Map from integer label to word label\n",
    "label_map = {\"1\":\"spam\", \"0\":\"ham\"}\n",
    "# Regex split objects with specified delimiters (space, period, comma)\n",
    "regex_beg = re.compile(r'^[\\s.,\"]+')\n",
    "regex_end = re.compile(r'[\\s.,\"]+$')\n",
    "regex_split = re.compile(r'[\\s.,]+')\n",
    "\n",
    "# Load wordcounts from 2.3 in memory\n",
    "wordcounts = {\"spam\": defaultdict(int), \"ham\": defaultdict(int)}\n",
    "with open(\"wordcounts_2_3.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        word, label, count = line.strip().split(\"\\t\")\n",
    "        wordcounts[label][word] = int(count)\n",
    "# Calculate total number of terms\n",
    "terms_spam = sum(wordcounts['spam'].values())\n",
    "terms_ham = sum(wordcounts['ham'].values())\n",
    "# Calculate priors and size of vocab\n",
    "prior_spam = wordcounts['spam']['*numdocs'] / (wordcounts['spam']['*numdocs'] + wordcounts['ham']['*numdocs'])\n",
    "prior_ham = 1 - prior_spam\n",
    "vocab_size = len(set(wordcounts['spam']).union(set(wordcounts['ham'])))\n",
    "\n",
    "# Process each document\n",
    "for line in sys.stdin:\n",
    "    line = line.strip().lower()\n",
    "    # Some lines have missing subjects\n",
    "    if len(line.split(\"\\t\")) == 4:\n",
    "        doc_id, label, subject, body = line.split(\"\\t\")\n",
    "    else:\n",
    "        subject = \"na\"\n",
    "        doc_id, label, body = line.split(\"\\t\")\n",
    "    # Remove delimiters at beginning and end of subjects and body\n",
    "    subject = regex_beg.sub('', subject)\n",
    "    subject = regex_end.sub('', subject)\n",
    "    body = regex_beg.sub('', body)\n",
    "    body = regex_end.sub('', body)\n",
    "    # Split into words\n",
    "    words = regex_split.split(subject + \" \" + body)\n",
    "    \n",
    "    # Initialize probabilities with priors\n",
    "    log_probs = {\"spam\": math.log(prior_spam), \"ham\": math.log(prior_ham)}\n",
    "    # Iterate through each word and add probabilities\n",
    "    for word in words:\n",
    "        # Laplace smoothing\n",
    "        log_probs[\"spam\"] += math.log((wordcounts['spam'][word] + 1) / \n",
    "                                      (terms_spam + vocab_size))\n",
    "        log_probs[\"ham\"] += math.log((wordcounts['ham'][word] + 1) / \n",
    "                                     (terms_ham + vocab_size))\n",
    "\n",
    "    # Classify\n",
    "    predicted_label = \"1\" if log_probs[\"spam\"] > log_probs[\"ham\"] else \"0\"\n",
    "    # Normalize probabilities for output, prevent overflow\n",
    "    if log_probs[\"ham\"] - log_probs[\"spam\"] > 700:\n",
    "            probs_spam = 0\n",
    "    else:\n",
    "        probs_spam = 1 / (1 + math.exp(log_probs[\"ham\"] - log_probs[\"spam\"]))\n",
    "    probs_ham = 1 - probs_spam\n",
    "    \n",
    "    # Output (DocID, label, predicted label, p_spam, p_ham)\n",
    "    print '\\t'.join([doc_id, label, predicted_label, \n",
    "                     str(probs_spam), str(probs_ham)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 16:42:15 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "16/01/24 16:42:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "packageJobJar: [/Users/InfernoIX/wordcounts_2_3.txt, /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/hadoop-unjar5566856366020640196/] [] /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/streamjob3587086667827603933.jar tmpDir=null\n",
      "16/01/24 16:42:17 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 16:42:17 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 16:42:18 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/01/24 16:42:18 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/01/24 16:42:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1453657675452_0010\n",
      "16/01/24 16:42:19 INFO impl.YarnClientImpl: Submitted application application_1453657675452_0010\n",
      "16/01/24 16:42:19 INFO mapreduce.Job: The url to track the job: http://Konniams-MacBook-Air.local:8088/proxy/application_1453657675452_0010/\n",
      "16/01/24 16:42:19 INFO mapreduce.Job: Running job: job_1453657675452_0010\n",
      "16/01/24 16:42:27 INFO mapreduce.Job: Job job_1453657675452_0010 running in uber mode : false\n",
      "16/01/24 16:42:27 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/01/24 16:42:37 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "16/01/24 16:42:38 INFO mapreduce.Job: Job job_1453657675452_0010 completed successfully\n",
      "16/01/24 16:42:38 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=236380\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=217192\n",
      "\t\tHDFS: Number of bytes written=4474\n",
      "\t\tHDFS: Number of read operations=10\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16122\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=16122\n",
      "\t\tTotal vcore-seconds taken by all map tasks=16122\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=16508928\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=100\n",
      "\t\tMap output records=100\n",
      "\t\tInput split bytes=224\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=324\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "\t\tTotal committed heap usage (bytes)=187170816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=216968\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4474\n",
      "16/01/24 16:42:38 INFO streaming.StreamJob: Output directory: /user/konniam/week_02/hw_2_4_output_classify\n"
     ]
    }
   ],
   "source": [
    "# Run MapReduce job\n",
    "# Map-only job. Pass in text file with wordcounts\n",
    "!hadoop jar hadoop-streaming-2.7.1.jar \\\n",
    "-D mapreduce.job.reduces=0 \\\n",
    "-mapper ~/mapper_classify.py \\\n",
    "-input /user/konniam/week_02/enronemail_1h.txt \\\n",
    "-output /user/konniam/week_02/hw_2_4_output_classify \\\n",
    "-file ~/wordcounts_2_3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 16:42:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "0011.2003-12-18.gp\t1\t1\t1.0\t0.0\n",
      "0011.2004-08-01.bg\t1\t1\t1.0\t0.0\n",
      "0012.1999-12-14.farmer\t0\t0\t3.04906108027e-156\t1.0\n",
      "0012.1999-12-14.kaminski\t0\t0\t2.5675875679e-107\t1.0\n",
      "0012.2000-01-17.beck\t0\t0\t8.15760689166e-266\t1.0\n",
      "0012.2000-06-08.lokay\t0\t0\t4.71892179913e-09\t0.999999995281\n",
      "0012.2001-02-09.kitchen\t0\t0\t2.59286926427e-14\t1.0\n",
      "0012.2003-12-19.gp\t1\t1\t0.99999901192\t9.88080343989e-07\n",
      "0013.1999-12-14.farmer\t0\t0\t1.94778405505e-69\t1.0\n",
      "0013.1999-12-14.kaminski\t0\t0\t3.59263723869e-120\t1.0\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_4_output_classify/part* | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 16:42:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "# Copy file back to local directory\n",
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_4_output_classify/part* > hw_2_4_results.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Error Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 0.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAALPCAYAAACHTs05AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6JYYBgCgW2IYAIBuiWEAALr1vwCaLrg8wJyLZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cc98a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hw_2_4_error():\n",
    "    # Parse results\n",
    "    columns = ['docid', 'label', 'preds', 'probs_spam', 'probs_ham']\n",
    "    df = pd.read_table(\"hw_2_4_results.txt\", header=None, names=columns)    \n",
    "    # Calculate error rate and output\n",
    "    print \"The training error is {}.\".format(np.mean(df['label'] != df['preds']))\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(211)\n",
    "    sns.distplot(df['probs_spam'], bins = 20, kde=None)\n",
    "    plt.subplot(212)\n",
    "    sns.distplot(df['probs_ham'], bins = 20, kde=None)\n",
    "\n",
    "hw_2_4_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Laplace smoothing, the model produced a training error of 0%, a drop from the previous erorr of 11%. In the case without smoothing, we skipped over many terms that don't have conditional probabilities in one class. However, such terms are valuable precisely because of this. For instance, \"lottery\" might have appeared 20 times in spam but not ham. Thus, \"lottery\" is a great predictor of the class. Laplace smoothing allows such terms to be included and we expected the in-sample error rate to improve.  \n",
    "  \n",
    "Nonetheless, we should not get too excited about 0% error because we have over 7000 parameters and only 100 examples. There likely is a substantial amount of overfitting and we don't expect the out-of-sample performance to be great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.5.\n",
    "Repeat HW2.4. This time when modeling and classification ignore tokens with a frequency of less than three (3) in the training set. How does it affect the misclassifcation error of learnt naive multinomial Bayesian Classifier on the training dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Strategy\n",
    "Like HW2.4, we can use the wordcount data from the 1st MR job from 2.3. We first change the vocab dictionary in our classifier mapper. Then we'll have to skip these terms in the prediction step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/mapper_classify.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/mapper_classify.py\n",
    "#!/usr/bin/env python\n",
    "## mapper_classify.py\n",
    "## Author: Konniam Chan\n",
    "## Description: classification (with Laplace smoothing, ignore infrequent terms) \n",
    "## mapper code for HW2.5\n",
    "from __future__ import division\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# Map from integer label to word label\n",
    "label_map = {\"1\":\"spam\", \"0\":\"ham\"}\n",
    "# Regex split objects with specified delimiters (space, period, comma)\n",
    "regex_beg = re.compile(r'^[\\s.,\"]+')\n",
    "regex_end = re.compile(r'[\\s.,\"]+$')\n",
    "regex_split = re.compile(r'[\\s.,]+')\n",
    "\n",
    "# Load wordcounts from 2.3 in memory\n",
    "wordcounts = {\"spam\": defaultdict(int), \"ham\": defaultdict(int)}\n",
    "with open(\"wordcounts_2_3.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        word, label, count = line.strip().split(\"\\t\")\n",
    "        wordcounts[label][word] = int(count)\n",
    "# Drop terms with total frequencies less than 3\n",
    "vocab_set = set(wordcounts['spam']).union(set(wordcounts['ham']))\n",
    "for word in vocab_set:\n",
    "    if (wordcounts['spam'][word] + wordcounts['ham'][word]) < 3:\n",
    "        del wordcounts['spam'][word]\n",
    "        del wordcounts['ham'][word]\n",
    "# Update vocabulary after deletion    \n",
    "vocab_set = set(wordcounts['spam']).union(set(wordcounts['ham']))        \n",
    "vocab_size = len(vocab_set)\n",
    "\n",
    "# Calculate total number of terms\n",
    "terms_spam = sum(wordcounts['spam'].values())\n",
    "terms_ham = sum(wordcounts['ham'].values())\n",
    "# Calculate priors and size of vocab\n",
    "prior_spam = wordcounts['spam']['*numdocs'] / (wordcounts['spam']['*numdocs'] + wordcounts['ham']['*numdocs'])\n",
    "prior_ham = 1 - prior_spam\n",
    "\n",
    "\n",
    "# Process each document\n",
    "for line in sys.stdin:\n",
    "    line = line.strip().lower()\n",
    "    # Some lines have missing subjects\n",
    "    if len(line.split(\"\\t\")) == 4:\n",
    "        doc_id, label, subject, body = line.split(\"\\t\")\n",
    "    else:\n",
    "        subject = \"na\"\n",
    "        doc_id, label, body = line.split(\"\\t\")\n",
    "    # Remove delimiters at beginning and end of subjects and body\n",
    "    subject = regex_beg.sub('', subject)\n",
    "    subject = regex_end.sub('', subject)\n",
    "    body = regex_beg.sub('', body)\n",
    "    body = regex_end.sub('', body)\n",
    "    # Split into words\n",
    "    words = regex_split.split(subject + \" \" + body)\n",
    "    \n",
    "    # Initialize probabilities with priors\n",
    "    log_probs = {\"spam\": math.log(prior_spam), \"ham\": math.log(prior_ham)}\n",
    "    # Iterate through each word and add probabilities\n",
    "    for word in words:\n",
    "        # Skip words that aren't in the vocab (frequencies < 3)\n",
    "        if word not in wordcounts['spam'] and word not in wordcounts['ham']:\n",
    "            continue            \n",
    "        # Laplace smoothing\n",
    "        log_probs[\"spam\"] += math.log((wordcounts['spam'][word] + 1) / \n",
    "                                      (terms_spam + vocab_size))\n",
    "        log_probs[\"ham\"] += math.log((wordcounts['ham'][word] + 1) / \n",
    "                                     (terms_ham + vocab_size))\n",
    "\n",
    "    # Classify\n",
    "    predicted_label = \"1\" if log_probs[\"spam\"] > log_probs[\"ham\"] else \"0\"\n",
    "    # Normalize probabilities for output, prevent overflow\n",
    "    if log_probs[\"ham\"] - log_probs[\"spam\"] > 700:\n",
    "            probs_spam = 0\n",
    "    else:\n",
    "        probs_spam = 1 / (1 + math.exp(log_probs[\"ham\"] - log_probs[\"spam\"]))\n",
    "    probs_ham = 1 - probs_spam\n",
    "    \n",
    "    # Output (DocID, label, predicted label, p_spam, p_ham)\n",
    "    print '\\t'.join([doc_id, label, predicted_label, \n",
    "                     str(probs_spam), str(probs_ham)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 17:55:22 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "16/01/24 17:55:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "packageJobJar: [/Users/InfernoIX/wordcounts_2_3.txt, /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/hadoop-unjar5716633767149479767/] [] /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/streamjob2636118730995460103.jar tmpDir=null\n",
      "16/01/24 17:55:24 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 17:55:25 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/24 17:55:26 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/01/24 17:55:26 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/01/24 17:55:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1453657675452_0012\n",
      "16/01/24 17:55:27 INFO impl.YarnClientImpl: Submitted application application_1453657675452_0012\n",
      "16/01/24 17:55:27 INFO mapreduce.Job: The url to track the job: http://Konniams-MacBook-Air.local:8088/proxy/application_1453657675452_0012/\n",
      "16/01/24 17:55:27 INFO mapreduce.Job: Running job: job_1453657675452_0012\n",
      "16/01/24 17:55:36 INFO mapreduce.Job: Job job_1453657675452_0012 running in uber mode : false\n",
      "16/01/24 17:55:36 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/01/24 17:55:46 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "16/01/24 17:55:47 INFO mapreduce.Job: Job job_1453657675452_0012 completed successfully\n",
      "16/01/24 17:55:47 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=236380\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=217192\n",
      "\t\tHDFS: Number of bytes written=4739\n",
      "\t\tHDFS: Number of read operations=10\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=15923\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=15923\n",
      "\t\tTotal vcore-seconds taken by all map tasks=15923\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=16305152\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=100\n",
      "\t\tMap output records=100\n",
      "\t\tInput split bytes=224\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=321\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "\t\tTotal committed heap usage (bytes)=187695104\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=216968\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4739\n",
      "16/01/24 17:55:47 INFO streaming.StreamJob: Output directory: /user/konniam/week_02/hw_2_5_output_classify\n"
     ]
    }
   ],
   "source": [
    "# Run MapReduce job\n",
    "# Map-only job. Pass in text file with wordcounts\n",
    "!hadoop jar hadoop-streaming-2.7.1.jar \\\n",
    "-D mapreduce.job.reduces=0 \\\n",
    "-mapper ~/mapper_classify.py \\\n",
    "-input /user/konniam/week_02/enronemail_1h.txt \\\n",
    "-output /user/konniam/week_02/hw_2_5_output_classify \\\n",
    "-file ~/wordcounts_2_3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 17:56:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "0011.2003-12-18.gp\t1\t1\t1.0\t0.0\n",
      "0011.2004-08-01.bg\t1\t1\t1.0\t5.10702591328e-15\n",
      "0012.1999-12-14.farmer\t0\t0\t6.56589297435e-128\t1.0\n",
      "0012.1999-12-14.kaminski\t0\t0\t1.43801209308e-101\t1.0\n",
      "0012.2000-01-17.beck\t0\t0\t6.30592690511e-270\t1.0\n",
      "0012.2000-06-08.lokay\t0\t1\t0.827662523121\t0.172337476879\n",
      "0012.2001-02-09.kitchen\t0\t0\t1.40530534624e-08\t0.999999985947\n",
      "0012.2003-12-19.gp\t1\t1\t0.999972184144\t2.78158562613e-05\n",
      "0013.1999-12-14.farmer\t0\t0\t4.39797857303e-54\t1.0\n",
      "0013.1999-12-14.kaminski\t0\t0\t9.27075827653e-116\t1.0\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_5_output_classify/part* | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/24 17:56:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "# Copy file back to local directory\n",
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_5_output_classify/part* > hw_2_5_results.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Error Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 0.04.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAALPCAYAAACHTs05AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c31af10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hw_2_5_error():\n",
    "    # Parse results\n",
    "    columns = ['docid', 'label', 'preds', 'probs_spam', 'probs_ham']\n",
    "    df = pd.read_table(\"hw_2_5_results.txt\", header=None, names=columns)    \n",
    "    # Calculate error rate and output\n",
    "    print \"The training error is {}.\".format(np.mean(df['label'] != df['preds']))\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(211)\n",
    "    sns.distplot(df['probs_spam'], bins = 20, kde=None)\n",
    "    plt.subplot(212)\n",
    "    sns.distplot(df['probs_ham'], bins = 20, kde=None)\n",
    "\n",
    "hw_2_5_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training error went to 4% (up from 0% in HW2.4). By limiting our vocabulary to words with frequencies >= 3 (in each class), we effectively performed feature selection and lowered our model complexity due to the fewer number of parameters. As we see on the learning curve below (taken from Elements of Statistical Learning), the in-sample-error always drops as model complexity increases. In HW2.5, we traversed backwards on the learning curve from HW2.4. We expect our error to increase, matching our results. Nonetheless, we should keep in mind that we still have over 1500 features, which are still way too many for 100 examples. Our generalization likely won't be great because of the amount of overfitting.  \n",
    "![learning](learning_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.6 Benchmark your code with the Python SciKit-Learn implementation of the multinomial Naive Bayes algorithm\n",
    "\n",
    "It always a good idea to benchmark your solutions against publicly available libraries such as SciKit-Learn, The Machine Learning toolkit available in Python. In this exercise, we benchmark ourselves against the SciKit-Learn implementation of multinomial Naive Bayes.  For more information on this implementation see: http://scikit-learn.org/stable/modules/naive_bayes.html more  \n",
    "\n",
    "In this exercise, please complete the following:\n",
    "\n",
    "- Run the Multinomial Naive Bayes algorithm (using default settings) from SciKit-Learn over the same training data used in HW2.5 and report the misclassification error (please note some data preparation might be needed to get the Multinomial Naive Bayes algorithm from SkiKit-Learn to run over this dataset)\n",
    "- Prepare a table to present your results, where rows correspond to approach used (SkiKit-Learn versus your Hadoop implementation) and the column presents the training misclassification error\n",
    "- Explain/justify any differences in terms of training error rates over the dataset in HW2.5 between your Multinomial Naive Bayes implementation (in Map Reduce) versus the Multinomial Naive Bayes implementation in SciKit-Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import sklearn packages\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1357.\n",
      "The classification error is: 0.04.\n"
     ]
    }
   ],
   "source": [
    "def sklearn_NB(NB_model, vectorizer):\n",
    "    '''\n",
    "    Runs sklearn NB implentation on enron emails, using input choice of NB model and vectorizer\n",
    "    '''\n",
    "    # Load text file\n",
    "    doc_ids, labels, content = [], [], []\n",
    "    with open(\"enronemail_1h.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            # Some lines have missing subjects\n",
    "            if len(line.split(\"\\t\")) == 4:\n",
    "                doc_id, label, subject, body = line.split(\"\\t\")\n",
    "            else:\n",
    "                subject = \"na\"\n",
    "                doc_id, label, body = line.split(\"\\t\")\n",
    "            # Put into array format\n",
    "            doc_ids.append(doc_id)\n",
    "            labels.append(int(label))\n",
    "            content.append(subject + \" \" + body)\n",
    "    # Vectorize train_data\n",
    "    content_vector = vectorizer.fit_transform(content)\n",
    "    print \"Vocab size: {}.\".format(content_vector.shape[1])\n",
    "    # Classify with sklearn NB model\n",
    "    NB_model.fit(content_vector, labels)\n",
    "    preds = NB_model.predict(content_vector)\n",
    "    print \"The classification error is: {}.\".format(np.mean(np.array(labels) != preds))\n",
    "\n",
    "# MultinomialNB, using terms of frequencies >= 3\n",
    "sklearn_NB(MultinomialNB(), CountVectorizer(min_df=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Response\n",
    "\n",
    "| Model                                                                      | Training Error   |\n",
    "|----------------------------------------------------------------------------|------------------|\n",
    "| Multinomial NB, MapReduce implementation (HW2.5)                           | 0.04             |\n",
    "| Multinomial NB, Scikit-Learn Implementation (HW2.6)                        | 0.04             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MapReduce implementation performed the same as the sklearn implementation. The two models use different features. In the MapReduce implementation, we dropped terms with less than 3 occurrences, but kept all punctuations and numbers (besides the period and comma in position as delimiters). The sklearn implementation performed a more restrictive tokenization by removing all punctuation and any length-1 alphanumeric characters. The vocab size is 1357, compared to around 1800 for our MR model.  \n",
    "  \n",
    "From the above learning curve, we would expect the training error for the sklearn implementation to be a little higher. However, it is likely that the extra features that were removed are not predictive of the class and didn't affect training performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 2.6.1 OPTIONAL (note this exercise is a stretch HW and optional)\n",
    "- Run the Bernoulli Naive Bayes algorithm from SciKit-Learn (using default settings) over the same training data used in HW2.6 and report the misclassification error \n",
    "- Discuss the performance differences in terms of misclassification error rates over the dataset in HW2.5 between the  Multinomial Naive Bayes implementation in SciKit-Learn with the  Bernoulli Naive Bayes implementation in SciKit-Learn. Why such big differences. Explain. \n",
    "\n",
    "Which approach to Naive Bayes would you recommend for SPAM detection? Justify your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1357.\n",
      "The classification error is: 0.12.\n"
     ]
    }
   ],
   "source": [
    "# Run 2.6 with Bernoulli NB\n",
    "# BernoulliNB, using terms of frequencies >= 3 and binary features\n",
    "sklearn_NB(BernoulliNB(), CountVectorizer(min_df=3, binary=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.1 Response\n",
    "\n",
    "| Model                                                                      | Training Error   |\n",
    "|----------------------------------------------------------------------------|------------------|\n",
    "| Multinomial NB, MapReduce implementation (HW2.5)                           | 0.04             |\n",
    "| Multinomial NB, Scikit-Learn Implementation (HW2.6)                        | 0.04             |\n",
    "| Bernoulli NB, Scikit-Learn Implementation (HW2.6.1)                        | 0.12             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli NB model performed the worst, with a 12% error versus 4% for the multinomial models. Multinomial NB represents features as term occurrences, models probability with a multinomial distribution of terms, and only considers terms in the document. Bernoulli NB represents features as a binary vector (of whether a particular term appears in a document), models probability with a Bernoulli distribution, and considers both appearance and non-apperaance of terms in the document. Because Bernoulli NB does not use information about repeated occurrence of a word in a doc, it leaves a lot of information on the table during classification. Multinomial NB uses more information and represents the document in a more nuanced way.  \n",
    "\n",
    "For spam classification in emails, Multinomial NB works better, because multiple occurrences are likely to be important in predicting the class. There is a big difference between \"assistance\" appearing once and \"assistance\" appearing 5 times. Multinomial NB will take the 5 occurrences into account and assigns heavy probability to the spam class. On the other hand, Bernoulli NB only note the appearnce of \"assistance\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.7 OPTIONAL (note this exercise is a stretch HW and optional)\n",
    "\n",
    "The Enron SPAM data in the following folder enron1-Training-Data-RAW is in raw text form (with subfolders for SPAM and HAM that contain raw email messages in the following form:\n",
    "\n",
    "--- Line 1 contains the subject\n",
    "--- The remaining lines contain the body of the email message.\n",
    "\n",
    "In Python write a script to produce a TSV file called train-Enron-1.txt that has a similar format as the enronemail_1h.txt that you have been using so far. Please pay attend to funky characters and tabs. Check your resulting formated email data in Excel and in Python (e.g., count up the number of fields in each row; the number of SPAM mails and the number of HAM emails). Does each row correspond to an email record with four values? Note: use \"NA\" to denote empty field values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting enron_merge.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile enron_merge.py\n",
    "#!/usr/bin/env python\n",
    "from __future__ import unicode_literals\n",
    "import os\n",
    "import string\n",
    "import codecs\n",
    "\n",
    "# Home directory\n",
    "home_path = os.getcwd()\n",
    "os.chdir(os.path.join(home_path, \"enron1-training-data-raw\"))\n",
    "# Label mapping\n",
    "label_map = {\"spam\":\"1\", \"ham\":\"0\"}\n",
    "# Output\n",
    "out_path = os.path.join(home_path, \"train-Enron-1.txt\")\n",
    "\n",
    "# Iterate over directory\n",
    "with open(out_path, \"w\") as out_file:\n",
    "    for root, dirs, filenames in os.walk(os.getcwd()):\n",
    "        # Skip irrelevant folders\n",
    "        if not(root.endswith(\"spam\") or root.endswith(\"ham\")):\n",
    "            continue\n",
    "        # Spam and ham folders\n",
    "        for filename in filenames:            \n",
    "            # Skip Mac internal files\n",
    "            if filename.startswith(\".\"):\n",
    "                continue\n",
    "            # Process each file\n",
    "            doc_id, label, ext = os.path.basename(filename).rsplit(\".\", 2)\n",
    "            label = label_map[label]\n",
    "            # Ignore characters with non-standard coding\n",
    "            with codecs.open(os.path.join(root, filename), \"r\", encoding='utf-8', errors='replace') as email:                \n",
    "                # Only take printable characters\n",
    "                subject = email.readline()\n",
    "                subject = filter(lambda x: x in string.printable, subject)\n",
    "                subject = subject.strip().split(\"Subject: \")\n",
    "                if len(subject)!=2 or not subject[1]:\n",
    "                    subject = \"NA\"\n",
    "                else:                    \n",
    "                    subject = subject[1]\n",
    "                # Strip newlines to convert to string    \n",
    "                body = email.read()\n",
    "                body = filter(lambda x: x in string.printable, body)\n",
    "                body = body.strip().replace('\\r\\n', '')\n",
    "                if not body:\n",
    "                    body = \"NA\"\n",
    "            # Write to output file\n",
    "            out_file.write(('\\t'.join([doc_id, label, subject, body]) + '\\n').encode('ascii', 'replace'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!./enron_merge.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x enron_merge.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5172 train-Enron-1.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l train-Enron-1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001.1999-12-10.farmer\t0\tchristmas tree farm pictures\tNA\r\n",
      "0002.1999-12-13.farmer\t0\tvastar resources , inc .\tgary , production from the high island larger block a - 1 # 2 commenced onsaturday at 2 : 00 p . m . at about 6 , 500 gross . carlos expects between 9 , 500 and10 , 000 gross for tomorrow . vastar owns 68 % of the gross production .george x 3 - 6992- - - - - - - - - - - - - - - - - - - - - - forwarded by george weissman / hou / ect on 12 / 13 / 99 10 : 16am - - - - - - - - - - - - - - - - - - - - - - - - - - -daren j farmer12 / 10 / 99 10 : 38 amto : carlos j rodriguez / hou / ect @ ectcc : george weissman / hou / ect @ ect , melissa graves / hou / ect @ ectsubject : vastar resources , inc .carlos ,please call linda and get everything set up .i ' m going to estimate 4 , 500 coming up tomorrow , with a 2 , 000 increase eachfollowing day based on my conversations with bill fischer at bmar .d .- - - - - - - - - - - - - - - - - - - - - - forwarded by daren j farmer / hou / ect on 12 / 10 / 99 10 : 34am - - - - - - - - - - - - - - - - - - - - - - - - - - -enron north america corp .from : george weissman 12 / 10 / 99 10 : 00 amto : daren j farmer / hou / ect @ ectcc : gary bryan / hou / ect @ ect , melissa graves / hou / ect @ ectsubject : vastar resources , inc .darren ,the attached appears to be a nomination from vastar resources , inc . for thehigh island larger block a - 1 # 2 ( previously , erroneously referred to as the# 1 well ) . vastar now expects the well to commence production sometimetomorrow . i told linda harris that we ' d get her a telephone number in gascontrol so she can provide notification of the turn - on tomorrow . linda ' snumbers , for the record , are 281 . 584 . 3359 voice and 713 . 312 . 1689 fax .would you please see that someone contacts linda and advises her how tosubmit future nominations via e - mail , fax or voice ? thanks .george x 3 - 6992- - - - - - - - - - - - - - - - - - - - - - forwarded by george weissman / hou / ect on 12 / 10 / 99 09 : 44am - - - - - - - - - - - - - - - - - - - - - - - - - - -\" linda harris \" on 12 / 10 / 99 09 : 38 : 43 amto : george weissman / hou / ect @ ectcc :subject : hi a - 1 # 2effective 12 - 11 - 99| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || mscf / d | min ftp | time || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 4 , 500 | 9 , 925 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 6 , 000 | 9 , 908 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 8 , 000 | 9 , 878 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 10 , 000 | 9 , 840 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 12 , 000 | 9 , 793 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 14 , 000 | 9 , 738 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 16 , 000 | 9 , 674 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 18 , 000 | 9 , 602 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 20 , 000 | 9 , 521 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 22 , 000 | 9 , 431 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 24 , 000 | 9 , 332 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 26 , 000 | 9 , 224 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 28 , 000 | 9 , 108 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 30 , 000 | 8 , 982 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 32 , 000 | 8 , 847 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 34 , 000 | 8 , 703 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - || | | || 36 , 000 | 8 , 549 | 24 hours || | | || - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\r\n",
      "0003.1999-12-14.farmer\t0\tcalpine daily gas nomination\t- calpine daily gas nomination 1 . doc\r\n",
      "0004.1999-12-14.farmer\t0\tre : issue\tfyi - see note below - already done .stella- - - - - - - - - - - - - - - - - - - - - - forwarded by stella l morris / hou / ect on 12 / 14 / 99 10 : 18am - - - - - - - - - - - - - - - - - - - - - - - - - - -from : sherlyn schumack on 12 / 14 / 99 10 : 06 amto : stella l morris / hou / ect @ ectcc : howard b camp / hou / ect @ ectsubject : re : issuestella ,this has already been taken care of . you did this for me yesterday .thanks .howard b camp12 / 14 / 99 09 : 10 amto : stella l morris / hou / ect @ ectcc : sherlyn schumack / hou / ect @ ect , howard b camp / hou / ect @ ect , staceyneuweiler / hou / ect @ ect , daren j farmer / hou / ect @ ectsubject : issuestella ,can you work with stacey or daren to resolvehc- - - - - - - - - - - - - - - - - - - - - - forwarded by howard b camp / hou / ect on 12 / 14 / 99 09 : 08am - - - - - - - - - - - - - - - - - - - - - - - - - - -from : sherlyn schumack 12 / 13 / 99 01 : 14 pmto : howard b camp / hou / ect @ ectcc :subject : issuei have to create accounting arrangement for purchase from unocal energy atmeter 986782 . deal not tracked for 5 / 99 . volume on deal 114427 expired 4 / 99 .\r\n",
      "0005.1999-12-14.farmer\t0\tmeter 7268 nov allocation\tfyi .- - - - - - - - - - - - - - - - - - - - - - forwarded by lauri a allen / hou / ect on 12 / 14 / 99 12 : 17pm - - - - - - - - - - - - - - - - - - - - - - - - - - -kimberly vaughn12 / 10 / 99 02 : 54 pmto : lauri a allen / hou / ect @ ectcc : mary m smith / hou / ect @ ectsubject : meter 7268 nov allocationlauri . . i have put this on strangas gas until i can get a contract fromdaren .- - - - - - - - - - - - - - - - - - - - - - forwarded by kimberly vaughn / hou / ect on 12 / 10 / 99 01 : 52pm - - - - - - - - - - - - - - - - - - - - - - - - - - -lauri a allen12 / 09 / 99 01 : 20 pmto : kimberly vaughn / hou / ect @ ect , anita luong / hou / ect @ ectcc : howard b camp / hou / ect @ ect , mary m smith / hou / ect @ ectsubject : meter 7268 nov allocationkim / anita -a volume of 7247 mm shows to have been allocated to the reliant 201 contractfor november . there was no nomination for reliant at this point in novemberand , therefore , there should be no volume allocated to their contract .please make sure these volumes are moved off the reliant contract prior tonovember close .thanks .\r\n",
      "0007.1999-12-14.farmer\t0\tmcmullen gas for 11 / 99\tjackie ,since the inlet to 3 river plant is shut in on 10 / 19 / 99 ( the last day offlow ) :at what meter is the mcmullen gas being diverted to ?at what meter is hpl buying the residue gas ? ( this is the gas from teco ,vastar , vintage , tejones , and swift )i still see active deals at meter 3405 in path manager for teco , vastar ,vintage , tejones , and swifti also see gas scheduled in pops at meter 3404 and 3405 .please advice . we need to resolve this as soon as possible so settlementcan send out payments .thanks\r\n",
      "0009.1999-12-14.farmer\t0\tmeter 1517 - jan 1999\tgeorge ,i need the following done :jan 13zero out 012 - 27049 - 02 - 001 receipt package id 2666allocate flow of 149 to 012 - 64610 - 02 - 055 deliv package id 392jan 26zero out 012 - 27049 - 02 - 001 receipt package id 3011zero out 012 - 64610 - 02 - 055 deliv package id 392these were buybacks that were incorrectly nominated to transport contracts( ect 201 receipt )let me know when this is donehc\r\n",
      "0010.1999-12-14.farmer\t0\tduns number changes\tfyi- - - - - - - - - - - - - - - - - - - - - - forwarded by gary l payne / hou / ect on 12 / 14 / 99 02 : 35 pm- - - - - - - - - - - - - - - - - - - - - - - - - - -from : antoine v pierre 12 / 14 / 99 02 : 34 pmto : tommy j yanowski / hou / ect @ ect , kathryn bussell / hou / ect @ ect , gary lpayne / hou / ect @ ect , diane e niestrath / hou / ect @ ect , romeo d ' souza / hou / ect @ ect ,michael eiben / hou / ect @ ect , clem cernosek / hou / ect @ ect , scottygilbert / hou / ect @ ect , dave nommensen / hou / ect @ ect , david rohan / hou / ect @ ect ,kevin heal / cal / ect @ ect , richard pinion / hou / ect @ ectcc : mary g gosnell / hou / ect @ ect , jason moore / hou / ect @ ect , samuelschott / hou / ect @ ect , bernice rodriguez / hou / ect @ ectsubject : duns number changesi will be making these changes at 11 : 00 am on wednesday december 15 .if you do not agree or have a problem with the dnb number change pleasenotify me , otherwise i will make the change as scheduled .dunns number change :counterparty cp id numberfrom tocinergy resources inc . 62163 869279893 928976257energy dynamics management , inc . 69545 825854664 088889774south jersey resources group llc 52109 789118270 036474336transalta energy marketing ( us ) inc . 62413 252050406 255326837philadelphia gas works 33282 148415904 146907159thanks ,rennie3 - 7578\r\n",
      "0011.1999-12-14.farmer\t0\tking ranch\tthere are two fields of gas that i am having difficulty with in the unifysystem .1 . cage ranch - since there is no processing agreement that accomodates thisgas on king ranch , it is my understanding hpl is selling the liquids andking ranch is re - delivering to stratton . it is also my understanding thatthere is a . 05 cent feeto deliver this gas . we need a method to accomodate the volume flow on hplat meter 415 and 9643 . this gaswill not be reflected on trans . usage ticket # 123395 and # 95394 since it isnot being nominated from a processing agreement . we either , need to inputa point nom ( on hpl or krgp ) at these meters to match the nom at meter 9610 ,or a deal for purchase and sale ( if king ranch is taking title to the gas )needs to be input into sitara at these meters with the appropriate rate . ihave currently input a point nom on krgp to accomodate this flow , so we candivert some of this gas to the current interstate sales that are being made .2 . forest oil - there is a processing agreement that will accomodate flowfrom the meter ( 6396 ) into king ranch . it is myunderstanding that this agreement was originally setup until texaco hadtheir own processing agreement . i need confirmation that the gas from thismeter should be nominated on contract # ( 96006681 ) and that this agreementshould have been reassigned to hplc . ( it is currently still under hplr ) .if this gas is not nominated on the above transport agreement , then onceagain we need to accomodate the flow volume on the hpl pipe with either apoint nom or a sitara deal at meters 415 and 9643 .\r\n",
      "0012.1999-12-14.farmer\t0\tre : entex transistion\tthanks so much for the memo . i would like to reiterate my support on two keyissues :1 ) . thu - best of luck on this new assignment . howard has worked hard anddone a great job ! please don ' t be shy on asking questions . entex iscritical to the texas business , and it is critical to our team that we aretimely and accurate .2 ) . rita : thanks for setting up the account team . communication iscritical to our success , and i encourage you all to keep each other informedat all times . the p & l impact to our business can be significant .additionally , this is high profile , so we want to assure top quality .thanks to all of you for all of your efforts . let me know if there isanything i can do to help provide any additional support .rita wynne12 / 14 / 99 02 : 38 : 45 pmto : janet h wallis / hou / ect @ ect , ami chokshi / corp / enron @ enron , howard bcamp / hou / ect @ ect , thu nguyen / hou / ect @ ect , kyle r lilly / hou / ect @ ect , staceyneuweiler / hou / ect @ ect , george grant / hou / ect @ ect , julie meyers / hou / ect @ ectcc : daren j farmer / hou / ect @ ect , kathryn cordes / hou / ect @ ect , ritawynne / hou / ect , lisa csikos / hou / ect @ ect , brenda f herod / hou / ect @ ect , pamelachambers / corp / enron @ enronsubject : entex transistionthe purpose of the email is to recap the kickoff meeting held on yesterdaywith members from commercial and volume managment concernig the entex account :effective january 2000 , thu nguyen ( x 37159 ) in the volume managment group ,will take over the responsibility of allocating the entex contracts . howardand thu began some training this month and will continue to transition theaccount over the next few months . entex will be thu ' s primary accountespecially during these first few months as she learns the allocationsprocess and the contracts .howard will continue with his lead responsibilites within the group and beavailable for questions or as a backup , if necessary ( thanks howard for allyour hard work on the account this year ! ) .in the initial phases of this transistion , i would like to organize an entex\" account \" team . the team ( members from front office to back office ) wouldmeet at some point in the month to discuss any issues relating to thescheduling , allocations , settlements , contracts , deals , etc . this hopefullywill give each of you a chance to not only identify and resolve issues beforethe finalization process , but to learn from each other relative to yourrespective areas and allow the newcomers to get up to speed on the account aswell . i would encourage everyone to attend these meetings initially as ibelieve this is a critical part to the success of the entex account .i will have my assistant to coordinate the initial meeting for early 1 / 2000 .if anyone has any questions or concerns , please feel free to call me or stopby . thanks in advance for everyone ' s cooperation . . . . . . . . . . .julie - please add thu to the confirmations distributions list\r\n"
     ]
    }
   ],
   "source": [
    "!head train-Enron-1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.8 OPTIONAL\n",
    "Using Hadoop Map-Reduce write job(s) to perform the following:\n",
    "- Train a multinomial Naive Bayes Classifier with Laplace plus one smoothing using the data extracted in HW2.7 (i.e., train-Enron-1.txt). Use all white-space delimitted tokens as independent input variables (assume spaces, fullstops, commas as delimiters). Drop tokens with a frequency of less than three (3).\n",
    "- Test the learnt classifier using enronemail_1h.txt and report the misclassification error rate. Remember to use all white-space delimitted tokens as independent input variables (assume spaces, fullstops, commas as delimiters). How do we treat tokens in the test set that do not appear in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 20:40:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -put train-Enron-1.txt /user/konniam/week_02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Strategy\n",
    "Using the entire corpus producted in 2.7, we use a similar 2-step training/classifcation strategy to learn a NB model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/mapper.py\n",
    "#!/usr/bin/env python\n",
    "## mapper.py\n",
    "## Author: Konniam Chan\n",
    "## Description: mapper code for HW2.8\n",
    "from __future__ import unicode_literals\n",
    "import sys\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Map from integer label to word label\n",
    "label_map = {\"1\":\"spam\", \"0\":\"ham\"}\n",
    "# Dictionary to keep track of terms\n",
    "wordcounts = {\"spam\": Counter(), \"ham\": Counter()}\n",
    "# Regex split objects with specified delimiters (space, period, comma)\n",
    "regex_beg = re.compile(r'^[\\s.,\"]+')\n",
    "regex_end = re.compile(r'[\\s.,\"]+$')\n",
    "regex_split = re.compile(r'[\\s.,]+')\n",
    "\n",
    "# Process each document\n",
    "for line in sys.stdin:\n",
    "    # Lower case\n",
    "    line = line.strip().lower()\n",
    "    # Some lines have missing subjects\n",
    "    if len(line.split(\"\\t\")) == 4:\n",
    "        doc_id, label, subject, body = line.split(\"\\t\")\n",
    "    else:\n",
    "        subject = \"NA\"\n",
    "        doc_id, label, body = line.split(\"\\t\")\n",
    "    # Remove delimiters at beginning and end of subjects and body\n",
    "    subject = regex_beg.sub('', subject)\n",
    "    subject = regex_end.sub('', subject)\n",
    "    body = regex_beg.sub('', body)\n",
    "    body = regex_end.sub('', body)\n",
    "    # Split into words\n",
    "    words = regex_split.split(subject + \" \" + body)\n",
    "    # Sum words that go through each mapper\n",
    "    label = label_map[label]\n",
    "    wordcounts[label] += Counter(words)\n",
    "    # Increment number of documents\n",
    "    wordcounts[label][\"*numdocs\"] += 1\n",
    "# Delete any stray spaces\n",
    "del wordcounts['spam']['']\n",
    "del wordcounts['ham']['']\n",
    "# Output each word\n",
    "for label in wordcounts:\n",
    "    for word in wordcounts[label]:\n",
    "        print '%s\\t%s\\t%s'.encode('ascii', 'replace') % (word, label, wordcounts[label][word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/reducer.py\n",
    "#!/usr/bin/env python\n",
    "## reducer.py\n",
    "## Author: Konniam Chan\n",
    "## Description: reducer code for HW2.8\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "# Dictionary to keep track of terms\n",
    "wordcounts = {\"spam\": Counter(), \"ham\": Counter()}\n",
    "# Process each tuple in the form of (word, spam/ham, count) separated by \\t\n",
    "for line in sys.stdin:\n",
    "    word, label, count = line.strip().split(\"\\t\")\n",
    "    wordcounts[label][word] += int(count)\n",
    "\n",
    "# Output each word\n",
    "for label in wordcounts:\n",
    "    for word in wordcounts[label]:\n",
    "        print '%s\\t%s\\t%s' % (word, label, wordcounts[label][word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 20:40:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "packageJobJar: [/var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/hadoop-unjar8638680243381962498/] [] /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/streamjob4305228516953118512.jar tmpDir=null\n",
      "16/01/25 20:40:59 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/25 20:40:59 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/25 20:41:00 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/01/25 20:41:00 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/01/25 20:41:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1453765434085_0006\n",
      "16/01/25 20:41:01 INFO impl.YarnClientImpl: Submitted application application_1453765434085_0006\n",
      "16/01/25 20:41:01 INFO mapreduce.Job: The url to track the job: http://Konniams-MacBook-Air.local:8088/proxy/application_1453765434085_0006/\n",
      "16/01/25 20:41:01 INFO mapreduce.Job: Running job: job_1453765434085_0006\n",
      "16/01/25 20:41:10 INFO mapreduce.Job: Job job_1453765434085_0006 running in uber mode : false\n",
      "16/01/25 20:41:11 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/01/25 20:41:26 INFO mapreduce.Job:  map 16% reduce 0%\n",
      "16/01/25 20:41:29 INFO mapreduce.Job:  map 21% reduce 0%\n",
      "16/01/25 20:41:32 INFO mapreduce.Job:  map 26% reduce 0%\n",
      "16/01/25 20:41:35 INFO mapreduce.Job:  map 29% reduce 0%\n",
      "16/01/25 20:41:38 INFO mapreduce.Job:  map 33% reduce 0%\n",
      "16/01/25 20:41:41 INFO mapreduce.Job:  map 34% reduce 0%\n",
      "16/01/25 20:41:44 INFO mapreduce.Job:  map 36% reduce 0%\n",
      "16/01/25 20:41:47 INFO mapreduce.Job:  map 37% reduce 0%\n",
      "16/01/25 20:41:53 INFO mapreduce.Job:  map 41% reduce 0%\n",
      "16/01/25 20:41:56 INFO mapreduce.Job:  map 42% reduce 0%\n",
      "16/01/25 20:42:02 INFO mapreduce.Job:  map 46% reduce 0%\n",
      "16/01/25 20:42:08 INFO mapreduce.Job:  map 47% reduce 0%\n",
      "16/01/25 20:42:14 INFO mapreduce.Job:  map 49% reduce 0%\n",
      "16/01/25 20:42:17 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "16/01/25 20:42:27 INFO mapreduce.Job:  map 52% reduce 0%\n",
      "16/01/25 20:42:30 INFO mapreduce.Job:  map 54% reduce 0%\n",
      "16/01/25 20:42:33 INFO mapreduce.Job:  map 55% reduce 0%\n",
      "16/01/25 20:42:38 INFO mapreduce.Job:  map 57% reduce 0%\n",
      "16/01/25 20:42:44 INFO mapreduce.Job:  map 60% reduce 0%\n",
      "16/01/25 20:42:53 INFO mapreduce.Job:  map 63% reduce 0%\n",
      "16/01/25 20:43:02 INFO mapreduce.Job:  map 66% reduce 0%\n",
      "16/01/25 20:43:14 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "16/01/25 20:43:16 INFO mapreduce.Job:  map 83% reduce 0%\n",
      "16/01/25 20:43:25 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "16/01/25 20:43:28 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "16/01/25 20:43:29 INFO mapreduce.Job: Job job_1453765434085_0006 completed successfully\n",
      "16/01/25 20:43:29 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1599080\n",
      "\t\tFILE: Number of bytes written=3550329\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5321872\n",
      "\t\tHDFS: Number of bytes written=1329445\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=255600\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=8751\n",
      "\t\tTotal time spent by all map tasks (ms)=255600\n",
      "\t\tTotal time spent by all reduce tasks (ms)=8751\n",
      "\t\tTotal vcore-seconds taken by all map tasks=255600\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=8751\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=261734400\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=8961024\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5172\n",
      "\t\tMap output records=91474\n",
      "\t\tMap output bytes=1416125\n",
      "\t\tMap output materialized bytes=1599086\n",
      "\t\tInput split bytes=224\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=76300\n",
      "\t\tReduce shuffle bytes=1599086\n",
      "\t\tReduce input records=91474\n",
      "\t\tReduce output records=84938\n",
      "\t\tSpilled Records=182948\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=373\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "\t\tTotal committed heap usage (bytes)=477626368\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=5321648\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1329445\n",
      "16/01/25 20:43:29 INFO streaming.StreamJob: Output directory: /user/konniam/week_02/hw_2_8_output\n"
     ]
    }
   ],
   "source": [
    "# Run MapReduce job\n",
    "# Specify 1 reducer\n",
    "!hadoop jar hadoop-streaming-2.7.1.jar \\\n",
    "-D mapreduce.job.reduces=1 \\\n",
    "-mapper ~/mapper.py \\\n",
    "-reducer ~/reducer.py \\\n",
    "-input /user/konniam/week_02/train-Enron-1.txt \\\n",
    "-output /user/konniam/week_02/hw_2_8_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 20:43:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "!\tham\t683\n",
      "!\tspam\t1288\n",
      "!\"\tspam\t1\n",
      "!$\tham\t1\n",
      "!$\tspam\t2\n",
      "!$68\tspam\t1\n",
      "!%\tspam\t11\n",
      "!'\tspam\t1\n",
      "!(\tham\t7\n",
      "!(\tspam\t1\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_8_output/part* | sort -k1,1 | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above MR job trained the model by obtaining the counts of all terms in either spam or ham.  \n",
    "We can now pass the result file from above when we want to classify our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 21:48:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "   84938\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_8_output/part* | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 22:06:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "# Save wordcounts to file on local drive\n",
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_8_output/part* > ~/wordcounts_2_8.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 2nd-stage MR job to classify the small email set, using the entire corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/InfernoIX/mapper_classify.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/mapper_classify.py\n",
    "#!/usr/bin/env python\n",
    "## mapper_classify.py\n",
    "## Author: Konniam Chan\n",
    "## Description: classification (with Laplace smoothing, ignore infrequent terms) \n",
    "## mapper code for HW2.8\n",
    "from __future__ import division\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# Map from integer label to word label\n",
    "label_map = {\"1\":\"spam\", \"0\":\"ham\"}\n",
    "# Regex split objects with specified delimiters (space, period, comma)\n",
    "regex_beg = re.compile(r'^[\\s.,\"]+')\n",
    "regex_end = re.compile(r'[\\s.,\"]+$')\n",
    "regex_split = re.compile(r'[\\s.,]+')\n",
    "\n",
    "# Load wordcounts from 2.8 in memory\n",
    "wordcounts = {\"spam\": defaultdict(int), \"ham\": defaultdict(int)}\n",
    "with open(\"wordcounts_2_8.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        word, label, count = line.strip().split(\"\\t\")\n",
    "        wordcounts[label][word] = int(count)\n",
    "# Drop terms with total frequencies less than 3\n",
    "vocab_set = set(wordcounts['spam']).union(set(wordcounts['ham']))\n",
    "for word in vocab_set:\n",
    "    if (wordcounts['spam'][word] + wordcounts['ham'][word]) < 3:\n",
    "        del wordcounts['spam'][word]\n",
    "        del wordcounts['ham'][word]\n",
    "# Update vocabulary after deletion    \n",
    "vocab_set = set(wordcounts['spam']).union(set(wordcounts['ham']))        \n",
    "vocab_size = len(vocab_set)\n",
    "\n",
    "# Calculate total number of terms\n",
    "terms_spam = sum(wordcounts['spam'].values())\n",
    "terms_ham = sum(wordcounts['ham'].values())\n",
    "# Calculate priors and size of vocab\n",
    "prior_spam = wordcounts['spam']['*numdocs'] / (wordcounts['spam']['*numdocs'] + wordcounts['ham']['*numdocs'])\n",
    "prior_ham = 1 - prior_spam\n",
    "\n",
    "\n",
    "# Process each document\n",
    "for line in sys.stdin:\n",
    "    line = line.strip().lower()\n",
    "    # Some lines have missing subjects\n",
    "    if len(line.split(\"\\t\")) == 4:\n",
    "        doc_id, label, subject, body = line.split(\"\\t\")\n",
    "    else:\n",
    "        subject = \"na\"\n",
    "        doc_id, label, body = line.split(\"\\t\")\n",
    "    # Remove delimiters at beginning and end of subjects and body\n",
    "    subject = regex_beg.sub('', subject)\n",
    "    subject = regex_end.sub('', subject)\n",
    "    body = regex_beg.sub('', body)\n",
    "    body = regex_end.sub('', body)\n",
    "    # Split into words\n",
    "    words = regex_split.split(subject + \" \" + body)\n",
    "    \n",
    "    # Initialize probabilities with priors\n",
    "    log_probs = {\"spam\": math.log(prior_spam), \"ham\": math.log(prior_ham)}\n",
    "    # Iterate through each word and add probabilities\n",
    "    for word in words:\n",
    "        # Skip words that aren't in the vocab\n",
    "        if word not in wordcounts['spam'] and word not in wordcounts['ham']:\n",
    "            continue            \n",
    "        # Laplace smoothing\n",
    "        log_probs[\"spam\"] += math.log((wordcounts['spam'][word] + 1) / \n",
    "                                      (terms_spam + vocab_size))\n",
    "        log_probs[\"ham\"] += math.log((wordcounts['ham'][word] + 1) / \n",
    "                                     (terms_ham + vocab_size))\n",
    "\n",
    "    # Classify\n",
    "    predicted_label = \"1\" if log_probs[\"spam\"] > log_probs[\"ham\"] else \"0\"\n",
    "    # Normalize probabilities for output, prevent overflow\n",
    "    if log_probs[\"ham\"] - log_probs[\"spam\"] > 700:\n",
    "            probs_spam = 0\n",
    "    else:\n",
    "        probs_spam = 1 / (1 + math.exp(log_probs[\"ham\"] - log_probs[\"spam\"]))\n",
    "    probs_ham = 1 - probs_spam\n",
    "    \n",
    "    # Output (DocID, label, predicted label, p_spam, p_ham)\n",
    "    print '\\t'.join([doc_id, label, predicted_label, \n",
    "                     str(probs_spam), str(probs_ham)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 22:09:35 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "16/01/25 22:09:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "packageJobJar: [/Users/InfernoIX/wordcounts_2_8.txt, /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/hadoop-unjar5326725080188935528/] [] /var/folders/l8/h51_59852qscq403fs6q0xlh0000gn/T/streamjob5623131734998070025.jar tmpDir=null\n",
      "16/01/25 22:09:37 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/25 22:09:37 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/01/25 22:09:38 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/01/25 22:09:38 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/01/25 22:09:38 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1453765434085_0008\n",
      "16/01/25 22:09:39 INFO impl.YarnClientImpl: Submitted application application_1453765434085_0008\n",
      "16/01/25 22:09:39 INFO mapreduce.Job: The url to track the job: http://Konniams-MacBook-Air.local:8088/proxy/application_1453765434085_0008/\n",
      "16/01/25 22:09:39 INFO mapreduce.Job: Running job: job_1453765434085_0008\n",
      "16/01/25 22:09:49 INFO mapreduce.Job: Job job_1453765434085_0008 running in uber mode : false\n",
      "16/01/25 22:09:49 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/01/25 22:10:01 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "16/01/25 22:10:02 INFO mapreduce.Job: Job job_1453765434085_0008 completed successfully\n",
      "16/01/25 22:10:03 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=236382\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=217192\n",
      "\t\tHDFS: Number of bytes written=4632\n",
      "\t\tHDFS: Number of read operations=10\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=20404\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=20404\n",
      "\t\tTotal vcore-seconds taken by all map tasks=20404\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=20893696\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=100\n",
      "\t\tMap output records=100\n",
      "\t\tInput split bytes=224\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=433\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "\t\tTotal committed heap usage (bytes)=188219392\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=216968\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4632\n",
      "16/01/25 22:10:03 INFO streaming.StreamJob: Output directory: /user/konniam/week_02/hw_2_8_output_classify\n"
     ]
    }
   ],
   "source": [
    "# Run MapReduce job\n",
    "# Map-only job. Pass in text file with wordcounts\n",
    "!hadoop jar hadoop-streaming-2.7.1.jar \\\n",
    "-D mapreduce.job.reduces=0 \\\n",
    "-mapper ~/mapper_classify.py \\\n",
    "-input /user/konniam/week_02/enronemail_1h.txt \\\n",
    "-output /user/konniam/week_02/hw_2_8_output_classify \\\n",
    "-file ~/wordcounts_2_8.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 23:55:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "0011.2003-12-18.gp\t1\t1\t1.0\t0.0\n",
      "0011.2004-08-01.bg\t1\t1\t1.0\t0.0\n",
      "0012.1999-12-14.farmer\t0\t0\t5.31855091372e-127\t1.0\n",
      "0012.1999-12-14.kaminski\t0\t0\t1.31343541076e-29\t1.0\n",
      "0012.2000-01-17.beck\t0\t0\t1.53420842707e-39\t1.0\n",
      "0012.2000-06-08.lokay\t0\t1\t1.0\t4.04121180964e-14\n",
      "0012.2001-02-09.kitchen\t0\t0\t6.46025337376e-10\t0.999999999354\n",
      "0012.2003-12-19.gp\t1\t1\t0.999999983328\t1.66724848372e-08\n",
      "0013.1999-12-14.farmer\t0\t0\t1.84396706319e-35\t1.0\n",
      "0013.1999-12-14.kaminski\t0\t0\t4.83587857574e-19\t1.0\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_8_output_classify/* | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2.8.1 OPTIONAL\n",
    "- Run  both the Multinomial Naive Bayes and the Bernoulli Naive Bayes algorithms from SciKit-Learn (using default settings) over the same training data used in HW2.8 and report the misclassification error on both the training set and the testing set\n",
    "- Prepare a table to present your results, where rows correspond to approach used (SciKit-Learn Multinomial NB; SciKit-Learn Bernouili NB; Your Hadoop implementation)  and the columns presents the training misclassification error, and the misclassification error on the test data set\n",
    "- Discuss the performance differences in terms of misclassification error rates over the test and training datasets by the different implementations. Which approch (Bernouili versus Multinomial) would you recommend for SPAM detection? Justify your selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8.1 Error Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/25 22:15:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/konniam/week_02/hw_2_8_output_classify/part* > hw_2_8_results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 0.12.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAALPCAYAAACHTs05AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+Q5Xdd5/tXT4YmmZnOJCsNK5ICF+SzWwpqEFgiJhMJ\nuKFCxVWrvAIrYLkLEqzsyr0i0cW11lpZMFyRAhYjGHRZt4osy4/FuEDEzMoVuIC1kATeEL0oy+7C\nkB8z3TOZyY/u+8c5U3Z6evp0n/Tp05nP41GV4vz69vfN9KfOPOfb39PfmeXl5QAAQI92TXsAAACY\nFjEMAEC3xDAAAN0SwwAAdEsMAwDQLTEMAEC3do96QWvttUlekGQ2yduSHExyfZKlJLckuaqq/H42\nAAAedtY9MtxaO5DkWVV1UZJLklyQ5Nok11TVxUlmklw56SEBAGASRp0m8bwkX2itvT/Jh5L8lyRP\nq6qDw+dvTHLZBOcDAICJGXWaxHwGR4OvSPL3MgjimRXPLybZP5nRAABgskbF8LeSfLGq7k/y5dba\n8STfseL5uSR3j9rJ8vLy8szMzKiXAQDAQ7Hp4BwVw3+W5Ookb2qtPTbJniQ3tdYuqaqbk1ye5KaR\nU83M5NChhc3Oxhlufn7OuuAU1gWrWROsxbpgLfPzc5veZt0YrqoPt9Yubq19OoPzi1+Z5KtJrmut\nzSa5LckNmx8VAACmb+SvVquq16zx8IGtHwUAALaXi24AANAtMQwAQLfEMAAA3RLDAAB0SwwDANAt\nMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0\nSwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANCt3dMeAACAh7elpaUsLi5Me4zMz89tehsxDADAQ7K4\nuJCPfur2nLNn79RmuOfY0TzxiY/b9HZiGACAh+ycPXuzZ+/mj8xOm3OGAQDolhgGAKBbYhgAgG6J\nYQAAuiWGAQDolhgGAKBbYhgAgG6JYQAAuiWGAQDolhgGAKBbYhgAgG6JYQAAuiWGAQDolhgGAKBb\nYhgAgG6JYQAAuiWGAQDolhgGAKBbYhgAgG7t3siLWmufS3J4ePevkvxGkuuTLCW5JclVVbU8iQEB\nAGBSRsZwa+3sJKmqS1c89sEk11TVwdba25NcmeT9E5sSAAAmYCNHhr83yZ7W2n8dvv6Xk1xYVQeH\nz9+Y5HkRwwAAPMxs5Jzho0neWFU/kuQVSd6z6vnFJPu3ejAAAJi0jRwZ/nKS25Okqr7SWrsjyfev\neH4uyd2jvsj8/NxYA3Jmsy5Yi3XBatYEa7Eudo7Z2aXs23tn9u47e2oz7Mq9Y223kRj+mSRPSXJV\na+2xGcTvR1prl1TVzUkuT3LTqC9y6NDCWANy5pqfn7MuOIV1wWrWBGuxLnaWI0cWsnj0RJZyfGoz\nHDt6YqztNhLD70xyfWvtvyVZTvKyJHckua61NpvktiQ3jLV3AACYopExXFX3JXnRGk8d2PJpAABg\nG7noBgAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwD\nANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLD\nAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfE\nMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3dq9HTv5fz5zaw7f\nfWw7dnVaF/zdb8tjHjM/1RkAANhZtiWGj9y3N4vLZ23Hrk7rriMLYhgAgAfZUAy31h6d5LNJnpNk\nKcn1w/+9JclVVbU8qQEBAGBSRp4z3Fp7RJJ3JDmaZCbJm5JcU1UXD+9fOdEJAQBgQjbyAbo3Jnl7\nkv81vH9hVR0c3r4xyWWTGAwAACZt3Rhurb00yaGq+sjwoZnhfyctJtk/mdEAAGCyRp0z/LIky621\ny5J8X5J3J1n5KbS5JHdvZEdz+84ea8Ctcv55Z2V+fm6qM3Aq3xPWYl2wmjXBWqyLnWN2din79t6Z\nvVPsvV25d6zt1o3hqrrk5O3W2seTvCLJG1trl1TVzUkuT3LTRna0sHh8rAG3yl3LJ3Lo0MJUZ+DB\n5ufnfE84hXXBatYEa7EudpYjRxayePREljK93jt29MRY2232V6stJ3l1kutaa7NJbktyw1h7BgCA\nKdtwDFfVpSvuHtj6UQAAYHu5HDMAAN0SwwAAdEsMAwDQLTEMAEC3xDAAAN0SwwAAdEsMAwDQLTEM\nAEC3xDAAAN0SwwAAdEsMAwDQLTEMAEC3xDAAAN0SwwAAdEsMAwDQLTEMAEC3xDAAAN0SwwAAdEsM\nAwDQLTEMAEC3xDAAAN0SwwAAdEsMAwDQLTEMAEC3xDAAAN0SwwAAdEsMAwDQLTEMAEC3xDAAAN0S\nwwAAdEsMAwDQLTEMAEC3xDAAAN0SwwAAdEsMAwDQLTEMAEC3xDAAAN0SwwAAdEsMAwDQLTEMAEC3\nxDAAAN0SwwAAdGv3qBe01s5Kcl2SJydZTvKKJCeSXJ9kKcktSa6qquXJjQkAAFtvI0eGr0iyVFXP\nTvIrSf5NkmuTXFNVFyeZSXLl5EYEAIDJGBnDVfWBJC8f3n1CkruSPK2qDg4fuzHJZROZDgAAJmhD\n5wxX1QOttXcneXOS92RwNPikxST7JzAbAABM1Mhzhk+qqpe01h6T5NNJzl7x1FySu0dtP7fv7FEv\nmajzzzsr8/NzU52BU/mesBbrgtWsCdZiXewcs7NL2bf3zuydYu/tyr1jbbeRD9C9OMnjqur1Se5J\n8kCSz7TWLqmqm5NcnuSmUV9nYfH4WANulbuWT+TQoYWpzsCDzc/P+Z5wCuuC1awJ1mJd7CxHjixk\n8eiJLGV6vXfs6ImxttvIkeH3Jfm91trNSR6R5OokX0pyXWttNsltSW4Ya+8AADBFI2O4qo4l+ck1\nnjqw5dMAAMA2ctENAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6\nJYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACA\nbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYA\noFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYB\nAOiWGAYAoFu713uytfaIJO9K8vgkj0zy60m+mOT6JEtJbklyVVUtT3ZMAADYeqOODL8oyaGqujjJ\nP0ry1iTXJrlm+NhMkisnOyIAAEzGqBh+b5LXrXjtfUkurKqDw8duTHLZhGYDAICJWvc0iao6miSt\ntbkMwvhXkvzmipcsJtk/sekAAGCC1o3hJGmtXZDkfUneWlV/2Fp7w4qn55LcvZEdze07e7wJt8j5\n552V+fm5qc7AqXxPWIt1wWrWBGuxLnaO2dml7Nt7Z/ZOsfd25d6xthv1AbrHJPlIkldW1ceHD/9F\na+2Sqro5yeVJbtrIjhYWj4814Fa5a/lEDh1amOoMPNj8/JzvCaewLljNmmAt1sXOcuTIQhaPnshS\nptd7x46eGGu7UUeGr8ngNIjXtdZOnjt8dZLfbq3NJrktyQ1j7RkAAKZs1DnDV2cQv6sdmMg0AACw\njVx0AwCAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYB\nAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolh\nAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFti\nGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOjW\n7o28qLX2zCSvr6pLW2tPSnJ9kqUktyS5qqqWJzciAABMxsgjw621X0xyXZJHDh96U5JrquriJDNJ\nrpzceAAAMDkbOU3i9iQ/lkH4JsmFVXVwePvGJJdNYjAAAJi0kTFcVe9Lcv+Kh2ZW3F5Msn+rhwIA\ngO2woXOGV1lacXsuyd0b2Whu39lj7GrrnH/eWZmfn5vqDJzK94S1WBesZk2wFuti55idXcq+vXdm\n7xR7b1fuHWu7cWL4L1prl1TVzUkuT3LTRjZaWDw+xq62zl3LJ3Lo0MJUZ+DB5ufnfE84hXXBatYE\na7EudpYjRxayePREljK93jt29MRY220mhk/+xohXJ7mutTab5LYkN4y1ZwAAmLINxXBVfTXJRcPb\nX0lyYHIjAQDA9nDRDQAAuiWGAQDolhgGAKBbYhgAgG6JYQAAuiWGAQDolhgGAKBbYhgAgG6JYQAA\nuiWGAQDolhgGAKBbYhgAgG6JYQAAuiWGAQDolhgGAKBbYhgAgG6JYQAAuiWGAQDolhgGAKBbYhgA\ngG6JYQAAuiWGAQDolhgGAKBbYhgAgG6JYQAAuiWGAQDolhgGAKBbYhgAgG6JYQAAuiWGAQDolhgG\nAKBbYhgAgG6JYQAAuiWGAQDolhgGAKBbu6c9QE+WlpayuLgw7TGyb99cdu3y7yAAADG8jRYXF/LR\nT92ec/bsndoM9xw7muc+80k599z9U5sBAGCnEMPb7Jw9e7Nn79y0xwAAIM4ZBgCgY2IYAIBuOU0C\n2DEf7kySb/u26Z1TD/Bws1PevxcWjmR5aXnaY4xFDAM74sOdyeADnj/1qLn4oRXAxuyU9+87v/WN\n7Nl7bvbOnTvVOcYhhoEkPtwJ8HC1E96/jx1dnOr+H4qxYri1tivJ25I8NcmJJD9bVX+5lYMBAMCk\njfuzyB9NMltVFyX5pSTXbt1IAACwPcaN4R9M8sdJUlWfSvIDWzYRAABsk3HPGT43yZEV9x9ore2q\nqqW1XvyIBw7nrPvuGXNXW2Pp/rNy5Mjhqc6wsHAk9xw7OtUZ7jl2NAsLR0a/cBvMzi7lyJHpfwKW\nnbE2k8H6PHz4cO67zwfo+FveK1iLdTGwU96/j99zNLt27c6xo9P7noz75zCzvLz5X4PRWrs2ySer\n6r3D+1+rqgvGmgAAAKZk3MMvn0jy/CRprf3DJJ/fsokAAGCbjHuaxH9O8tzW2ieG91+2RfMAAMC2\nGes0CQAAOBP4lAoAAN0SwwAAdEsMAwDQrXE/QHeKUZdobq29IMm/THJ/kndV1e9u1b7ZuTawLn4q\nydUZrIsvJHllVTmR/Qy30Uu6t9Z+J8kdVfXabR6RKdjA+8XTM7ji6UyS/53kxVV1Yhqzsn02sC5e\nlOQXkjyQQV/8u6kMyrZrrT0zyeur6tJVj2+qObfyyPBpL9HcWntEkjcleW6SS5L8s9bao7dw3+xc\n662Lc5L86yQHqurZSfYnuWIqU7LdRl7SvbX28iTfk8Q/jvqx3vvFTJLfSfLSqvqhDK6C+vipTMl2\nG/V+8cYkz8ng6rivbq3t3+b5mILW2i8muS7JI1c9vunm3MoYXu8Szf8gye1Vdbiq7kvyZ0ku3sJ9\ns3Otty6OJ3lWVR0f3t+dZLqXKmS7rHtJ99baRUmekeQdGRwFpA/rrYsnJ7kjyS+01v40yd+pqi9v\n+4RMw7rvFxlc6+C8JOdk8H7hH9B9uD3Jj+XUvyM23ZxbGcNrXqJ5xXMrr4W8kMFRQM58p10XVbVc\nVYeSpLX280n2VtXHpjAj2++066K19u1JXpfkVRHCvVnv75FHJbkoyVuSXJbkOa21S0MP1lsXSXJr\nks8muSXJh6pq5Ws5Q1XV+zI4DWK1TTfnVsbwkSRzK792VS0Nbx9e9dxckru2cN/sXOuti7TWdrXW\nfjODH3H9+HYPx9Ssty5+IoPw+aMkr0nywtbaT2/zfEzHeuvijgyO9lRV3Z/BkcLVRwg5M512XbTW\nnprBFXEfn+QJSR7TWvuJbZ+QnWTTzbmVMbzeJZq/lOS7Wmvnt9ZmMzhc/edbuG92rlGX7n5HBuf7\n/OMVp0tw5jvtuqiqt1TVDww/EPH6JP+hqn5/OmOyzdZ7v/irJPtaa08c3v+hDI4EcuZbb10czuD0\nuhPDQP5mBqdM0K9NN+eWXYFu+OGGk5/2TAaXaH5akn1VdV1r7YoMfvS5K8k7q+rtW7JjdrT11kWS\nzwz/O7hikzdX1fu3dUi23aj3ixWve0mSVlXXbP+UbLcN/D1y8h9IM0k+UVX/YjqTsp02sC5enuRn\nktybwXmk/3T40wPOcK21J2RwwOSi4W+nGqs5XY4ZAIBuuegGAADdEsMAAHRLDAMA0C0xDABAt8Qw\nAADdEsMAAHRLDANMUGvtQGvt49OeA4C1iWEAALq1e9oDAOx0rbUDSX4tgytcXZDk00l+PckHkxzK\n4HKwP5LkzUl+OMlykj+oqjcMv8SjWms3JvmOJJ9KctXwNe9K8t3D17ytqn53nRmek+TfDre7K8lP\nJZlL8qEMrrr1XUn+OsmLq+qu1tqrkrw4yd4kS0l+sqq+1Fr7apL/mOSKJPcnuSbJ/5nkSUleXVXv\nHfOPCeBhyZFhgI15epJXVtXfT3J2BjH55CQvqqrnJfm5DGL3KUmekeTHW2vPH277nUleVVVPzSBg\nX5HkWUnOr6oLk1yW5AdH7P+Xk7y8qp6eQQB///Dx707yf1fV9yT5YpJ/1VqbS3Jlkkuq6ilJ3p/k\nlcPXLyf5+vD1n0vyS8P9vzjJa8f6kwF4GBPDABtzsKq+Mrz9BxkcAf5GVf3N8LFLk1xfVctVdU+S\n9yR5TgbxebCq/nL4uvckOZDkliSttfbHGYToa0bs/4NJ3t9ae0uSL1bVx4aPf7mqDg5vvzvJD1fV\nQpIXJnlha+03krwggyPEJ904/N+/TvKnVbWU5G+SnL/BPwuAM4YYBtiY+1fcPivJfRmcHnHSriQz\nq+6fPBXt/lWP31dVd2ZwVPctSVqSz7XW9p9u51X1WxlE9O1J3tBauyaD0F491/2ttccl+WSSc5N8\nOMn1q2a7d8XtB063T4AeiGGAjXl2a+2xrbVdSf5JBkdXVwbmnyR5SWttV2ttTwZHZv9k+Jpnt9Yu\nGG77kiQfba29IMm/r6oPJ7k6yWKSx51u5621TyaZq6o3J/mt/O1pEq219r3D2y9L8kcZnNLxleFr\n/98kz4/PiACsSQwDbMz/TPL7SW5N8j+SfCyDI7MnvWP4+H/P4FzcD1TVB4avuTWDD8t9PsnXkrwz\ng5i+p7V2awYfqvtPVXXrOvu/Jsn1rbXPJPnZJL+aQWjfmeTXWmu3JHlUBh/s+0iSXcOv/edJ/r8k\nTzjN110+zW2ALswsL3vvA1jP8LdJ/GpVXTrtWVZqrT0hycer6junPQvAw5UfmwGMtpxtOGraWvvn\nGZxGsdrXq+qK02zmiAbAQ+DIMAAA3XLOMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwD\nANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLD\nAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLd2j3pBa+21SV6QZDbJ25IcTHJ9kqUk\ntyS5qqqWJzgjAABMxLpHhltrB5I8q6ouSnJJkguSXJvkmqq6OMlMkisnPSQAAEzCqNMknpfkC621\n9yf5UJL/kuRpVXVw+PyNSS6b4HwAADAxo06TmM/gaPAVSf5eBkE8s+L5xST7JzMaAABM1qgY/laS\nL1bV/Um+3Fo7nuQ7Vjw/l+TuUTtZXl5enpmZGfUyAAB4KDYdnKNi+M+SXJ3kTa21xybZk+Sm1tol\nVXVzksuT3DRyqpmZHDq0sNnZOMPNz89ZF5zCumA1a4K1WBesZX5+btPbrBvDVfXh1trFrbVPZ3B+\n8SuTfDXJda212SS3Jblh86MCAMD0jfzValX1mjUePrD1owAAwPZy0Q0AALolhgEA6JYYBgCgW2IY\nAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYY\nBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALq1ezt28oXbvpy77zq2Hbs6rW//u4/K\n/nP3T3UGAAB2lm2J4a8fns3CsaXt2NXpfeMOMQwAwIM4TQIAgG6JYQAAuiWGAQDolhgGAKBbYhgA\ngG6JYQAAuiWGAQDolhgGAKBbYhgAgG6JYQAAuiWGAQDolhgGAKBbYhgAgG6JYQAAuiWGAQDolhgG\nAKBbYhgAgG6JYQAAuiWGAQDolhgGAKBbuzfyotba55IcHt79qyS/keT6JEtJbklyVVUtT2JAAACY\nlJEx3Fo7O0mq6tIVj30wyTVVdbC19vYkVyZ5/8SmBACACdjIkeHvTbKntfZfh6//5SQXVtXB4fM3\nJnlexDAAAA8zGzln+GiSN1bVjyR5RZL3rHp+Mcn+rR4MAAAmbSNHhr+c5PYkqaqvtNbuSPL9K56f\nS3L3qC8yt+/ssQbcKuefd1bm5+emOgOn8j1hLdYFq1kTrMW6YCtsJIZ/JslTklzVWntsBvH7kdba\nJVV1c5LLk9w06ossLB5/SIM+VHctn8ihQwtTnYEHm5+f8z3hFNYFq1kTrMW6YC3j/ANpIzH8ziTX\nt9b+W5LlJC9LckeS61prs0luS3LDpvcMAABTNjKGq+q+JC9a46kDWz4NAABsIxfdAACgW2IYAIBu\niWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCg\nW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA\n6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEA\nALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW7unPQAAAA9vS0tLWVxcmPYYmZ+f2/Q2\nYhgAgIdkcXEhH/3U7Tlnz96pzXDPsaN54hMft+ntNhTDrbVHJ/lskuckWUpy/fB/b0lyVVUtb3rP\nAACcMc7Zszd79m7+yOy0jTxnuLX2iCTvSHI0yUySNyW5pqouHt6/cqITAgDAhGzkA3RvTPL2JP9r\neP/Cqjo4vH1jkssmMRgAAEzaujHcWntpkkNV9ZHhQzPD/05aTLJ/MqMBAMBkjTpn+GVJlltrlyX5\nviTvTjK/4vm5JHdvZEdz+84ea8Ctcv55Z431CUMmy/eEtVgXrGZNsBbrYueYnV3Kvr13Zu8Ue29X\n7h1ru3VjuKouOXm7tfbxJK9I8sbW2iVVdXOSy5PctJEdLSweH2vArXLX8okcOjT9X/nB35qfn/M9\n4RTWBatZE6zFuthZjhxZyOLRE1nK9Hrv2NETY2232V+ttpzk1Umua63NJrktyQ1j7RkAAKZswzFc\nVZeuuHtg60cBAIDt5XLMAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLD\nAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfE\nMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAt\nMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0SwwDANAtMQwAQLfEMAAA3RLDAAB0\nSwwDANAtMQwAQLd2j3pBa+2sJNcleXKS5SSvSHIiyfVJlpLckuSqqlqe3JgAALD1NnJk+IokS1X1\n7CS/kuTfJLk2yTVVdXGSmSRXTm5EAACYjJExXFUfSPLy4d0nJLkrydOq6uDwsRuTXDaR6QAAYII2\ndM5wVT3QWnt3kjcneU8GR4NPWkyyfwKzAQDARI08Z/ikqnpJa+0xST6d5OwVT80luXvU9nP7zh71\nkok6/7yzMj8/N9UZOJXvCWuxLljNmmAt1sXOMTu7lH1778zeKfbertw71nYb+QDdi5M8rqpen+Se\nJA8k+Uxr7ZKqujnJ5UluGvV1FhaPjzXgVrlr+UQOHVqY6gw82Pz8nO8Jp7AuWM2aYC3Wxc5y5MhC\nFo+eyFKm13vHjp4Ya7uNHBl+X5Lfa63dnOQRSa5O8qUk17XWZpPcluSGsfYOAABTNDKGq+pYkp9c\n46kDWz4NAABsIxfdAACgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCg\nW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA\n6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEA\nALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IY\nAIBu7V7vydbaI5K8K8njkzwyya8n+WKS65MsJbklyVVVtTzZMQEAYOuNOjL8oiSHquriJP8oyVuT\nXJvkmuFjM0munOyIAAAwGaNi+L1JXrfitfclubCqDg4fuzHJZROaDQAAJmrd0ySq6miStNbmMgjj\nX0nymytesphk/8SmAwCACVo3hpOktXZBkvcleWtV/WFr7Q0rnp5LcvdGdjS37+zxJtwi5593Vubn\n56Y6A6fyPWEt1gWrWROsxbrYOWZnl7Jv753ZO8Xe25V7x9pu1AfoHpPkI0leWVUfHz78F621S6rq\n5iSXJ7mbSlVMAAALIUlEQVRpIztaWDw+1oBb5a7lEzl0aGGqM/Bg8/NzviecwrpgNWuCtVgXO8uR\nIwtZPHoiS5le7x07emKs7UYdGb4mg9MgXtdaO3nu8NVJfru1NpvktiQ3jLVnAACYslHnDF+dQfyu\ndmAi0wAAwDZy0Q0AALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALol\nhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBu\niWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCg\nW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA6JYYBgCgW2IYAIBuiWEAALolhgEA\n6JYYBgCgW7s38qLW2jOTvL6qLm2tPSnJ9UmWktyS5KqqWp7ciAAAMBkjjwy31n4xyXVJHjl86E1J\nrqmqi5PMJLlycuMBAMDkbOQ0iduT/FgG4ZskF1bVweHtG5NcNonBAABg0kbGcFW9L8n9Kx6aWXF7\nMcn+rR4KAAC2w4bOGV5lacXtuSR3b2SjuX1nj7GrrXP+eWdlfn5uqjNwKt8T1mJdsJo1wVqsi51j\ndnYp+/bemb1T7L1duXes7caJ4b9orV1SVTcnuTzJTRvZaGHx+Bi72jp3LZ/IoUMLU52BB5ufn/M9\n4RTWBatZE6zFuthZjhxZyOLRE1nK9Hrv2NETY223mRg++RsjXp3kutbabJLbktww1p4BAGDKNhTD\nVfXVJBcNb38lyYHJjQQAANvDRTcAAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolh\nAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFti\nGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6JYYBAOiW\nGAYAoFtiGACAbolhAAC6JYYBAOiWGAYAoFtiGACAbolhAAC6tXvaAwAAPBwtLS1lcXFh2mNk3765\n7Nrl+Oa4xDAAwBgWFxfy0U/dnnP27J3aDPccO5rnPvNJOffc/VOb4eFODAMAjOmcPXuzZ+/ctMfg\nIXBMHQCAbolhAAC61cVpEidPcD9y5PC0R3GSO8AmLC0t5fDhwzlyxIeUgMnoIoaP33M09TffzDeP\nPXKqczjJHWBzFhcX8pFPfi1Ly9P968r7N5y5xnp3aa3tSvK2JE9NciLJz1bVX27lYFvt7LP3OMEd\n4GFoz569WcrstMcAzlDj/rznR5PMVtVFSX4pybVbNxIAAGyPcWP4B5P8cZJU1aeS/MCWTQQAANtk\n3JOwzk1yZMX9B1pru6pqaa0XHzv8zRxbPD7mrh66Y0cXc+L48Rw7Ot0PYNxz7GgWFo6MfmEnZmeX\ndsSHYthZrAtWWlg4kmPHjmZp+cRU5/D+vfPshPeKhYUjuefY0anOsFPW5k75sxjHzPLy8qY3aq1d\nm+STVfXe4f2vVdUFY00AAABTMu5pEp9I8vwkaa39wySf37KJAABgm4x7msR/TvLc1tonhvdftkXz\nAADAthnrNAkAADgTuJQOAADdEsMAAHRLDAMA0K0tu9j7qEs0t9ZekORfJrk/ybuq6ne3at/sXBtY\nFz+V5OoM1sUXkryyqpzIfobb6CXdW2u/k+SOqnrtNo/IFGzg/eLpGVzxdCbJ/07y4qqa7i8gZuI2\nsC5elOQXkjyQQV/8u6kMyrZrrT0zyeur6tJVj2+qObfyyPBpL9HcWntEkjcleW6SS5L8s9bao7dw\n3+xc662Lc5L86yQHqurZSfYnuWIqU7LdRl7SvbX28iTfk8Q/jvqx3vvFTJLfSfLSqvqhDK6C+vip\nTMl2G/V+8cYkz8ng6rivbq3t3+b5mILW2i8muS7JI1c9vunm3MoYXu8Szf8gye1Vdbiq7kvyZ0ku\n3sJ9s3Otty6OJ3lWVZ28POHuJPds73hMybqXdG+tXZTkGUnekcFRQPqw3rp4cpI7kvxCa+1Pk/yd\nqvrytk/INKz7fpHBtQ7OS3JOBu8X/gHdh9uT/FhO/Tti0825lTG85iWaVzx3eMVzCxkcBeTMd9p1\nUVXLVXUoSVprP59kb1V9bAozsv1Ouy5aa9+e5HVJXhUh3Jv1/h55VJKLkrwlyWVJntNauzT0YL11\nkSS3JvlskluSfKiqpn9tYiauqt6XwWkQq226Obcyho8kmVv5tatqaXj78Krn5pLctYX7Zudab12k\ntbartfabGfyI68e3ezimZr118RMZhM8fJXlNkhe21n56m+djOtZbF3dkcLSnqur+DI4Urj5CyJnp\ntOuitfbUDK6I+/gkT0jymNbaT2z7hOwkm27OrYzh9S7R/KUk39VaO7+1NpvB4eo/38J9s3ONunT3\nOzI43+cfrzhdgjPfaddFVb2lqn5g+IGI1yf5D1X1+9MZk2223vvFXyXZ11p74vD+D2VwJJAz33rr\n4nAGp9edGAbyNzM4ZYJ+bbo5t+wKdMMPN5z8tGcyuETz05Lsq6rrWmtXZPCjz11J3llVb9+SHbOj\nrbcuknxm+N/BFZu8uarev61Dsu1GvV+seN1LkrSqumb7p2S7beDvkZP/QJpJ8omq+hfTmZTttIF1\n8fIkP5Pk3gzOI/2nw58ecIZrrT0hgwMmFw1/O9VYzelyzAAAdMtFNwAA6JYYBgCgW2IYAIBuiWEA\nALolhgEA6JYYBgCgW2IYYJu01g601j6+BV/nX7XWfnUrZgLonRgGePjxC+IBtsjuaQ8A8HDSWjuQ\n5NcyuNrVBUk+neTXk3wwyaEMLg37I0nenOSHMwjXP6iqNwy/xKNaazcm+Y4kn0py1fA170ry3cPX\nvK2qfnfEKM9orX1i+HV+r6p+rbV2bpJ3Dh97bJKDVfXTw5l/ebjdE5PckMFlbH80g6u5Pb+qvjnW\nHwjAw5wjwwCb9/Qkr6yqv5/k7CRXJHlykhdV1fOS/FwGQfqUJM9I8uOttecPt/3OJK+qqqcmmUvy\niiTPSnJ+VV2Y5LIkPzhi/zNJHp3kQAaXpf2/Wmv7kjw/yeeq6qLhPM9qrV043OYZSV6aQXD/XJJv\nVtXTk3w+yf8x/h8FwMObGAbYvINV9ZXh7T/I4AjwN6rqb4aPXZrk+qparqp7krwnyXMyOAJ8sKr+\ncvi692QQtLckaa21P07y4iSvGbH/5SQ3VtV9VXVHkm9lENP/MclNrbV/nuQtSb4tyd7hNrdU1deH\n83wryU3Dx/86yflj/SkAnAHEMMDm3b/i9llJ7svg9IiTdmVw9Hbl/ZOnpd2/6vH7qurODI7YviVJ\nS/K51tr+ETM8sOL2cpJdrbWfT/KGJN9I8ttJblsxx73r/H8A6JYYBti8Z7fWHtta25XknyS5MQ+O\n3z9J8pLW2q7W2p4kLxw+NjPc9oLhti9J8tHW2guS/Puq+nCSq5MsJnncGHNdluQdVfWHw/vfF58N\nAViXGAbYvP+Z5PeT3JrkfyT5WB78Gx7eMXz8vyf5XJIPVNUHhq+5NYMPy30+ydcy+MDbjUnuaa3d\nmsGH6v5TVd06YoblVbeXk/xWkl9trX02yVuTfCLJE1Y8v5GvBdCVmeVl74EAGzX8zQy/WlWXTnsW\nAB46Pz4D2JxRR1m3xPBDcC9Z46mvV9UVk94/QC8cGQYAoFvOGQYAoFtiGACAbolhAAC6JYYBAOiW\nGAYAoFtiGACAbv3//Wgz2EuUeokAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1091f05d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hw_2_8_error():\n",
    "    # Parse results\n",
    "    columns = ['docid', 'label', 'preds', 'probs_spam', 'probs_ham']\n",
    "    df = pd.read_table(\"hw_2_8_results.txt\", header=None, names=columns)    \n",
    "    # Calculate error rate and output\n",
    "    print \"The training error is {}.\".format(np.mean(df['label'] != df['preds']))\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(211)\n",
    "    sns.distplot(df['probs_spam'], bins = 20, kde=None)\n",
    "    plt.subplot(212)\n",
    "    sns.distplot(df['probs_ham'], bins = 20, kde=None)\n",
    "\n",
    "hw_2_8_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification error is: 0.07.\n"
     ]
    }
   ],
   "source": [
    "def hw_2_8_1(NB_model, binary_features=False):\n",
    "    '''\n",
    "    Runs sklearn NB implentation on enron emails, using input choice of NB model\n",
    "    '''\n",
    "    # Load train and test data\n",
    "    data = {\"train\": {\"path\":\"train-Enron-1.txt\", \"doc_ids\":[], \"labels\":[],\n",
    "                      \"content\":[]},   \n",
    "            \"test\": {\"path\": \"enronemail_1h.txt\", \"doc_ids\":[], \"labels\":[],\n",
    "                     \"content\":[]}}\n",
    "    vectorizer = CountVectorizer(min_df=3, binary=binary_features)\n",
    "    \n",
    "    # Vectorize train\n",
    "    with open(data[\"train\"][\"path\"], \"r\") as f:\n",
    "        for line in f:            \n",
    "            doc_id, label, subject, body = line.split(\"\\t\")\n",
    "            data[\"train\"][\"doc_ids\"].append(doc_id)\n",
    "            data[\"train\"][\"labels\"].append(int(label))\n",
    "            data[\"train\"][\"content\"].append(subject + \" \" + body)\n",
    "    # Vectorize\n",
    "    data[\"train\"][\"content_vector\"] = vectorizer.fit_transform(data[\"train\"][\"content\"])\n",
    "        \n",
    "    # Vectorize test data\n",
    "    with open(data[\"test\"][\"path\"], \"r\") as f:\n",
    "        for line in f:\n",
    "            # Some lines have missing subjects\n",
    "            if len(line.split(\"\\t\")) == 4:\n",
    "                doc_id, label, subject, body = line.split(\"\\t\")\n",
    "            else:\n",
    "                subject = \"NA\"\n",
    "                doc_id, label, body = line.split(\"\\t\")\n",
    "            # Put into array format\n",
    "            data[\"test\"][\"doc_ids\"].append(doc_id)\n",
    "            data[\"test\"][\"labels\"].append(int(label))\n",
    "            data[\"test\"][\"content\"].append(subject + \" \" + body)\n",
    "    # Vectorize\n",
    "    data[\"test\"][\"content_vector\"] = vectorizer.transform(data[\"test\"][\"content\"])\n",
    "\n",
    "    # Classify with sklearn NB model\n",
    "    NB_model.fit(data[\"train\"][\"content_vector\"], data[\"train\"][\"labels\"])\n",
    "    preds = NB_model.predict(data[\"test\"][\"content_vector\"])\n",
    "    print \"The classification error is: {}.\".format(np.mean(np.array(data[\"test\"][\"labels\"]) != preds))\n",
    "\n",
    "# MultinomialNB, using terms of frequencies >= 3\n",
    "hw_2_8_1(MultinomialNB(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification error is: 0.08.\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli NB\n",
    "hw_2_8_1(BernoulliNB(), binary_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8.1 Response\n",
    "\n",
    "| Model                                                                      | Training Error   |\n",
    "|----------------------------------------------------------------------------|------------------|\n",
    "| Multinomial NB, MapReduce implementation                                   | 0.12             |\n",
    "| Multinomial NB, Scikit-Learn Implementation                                | 0.07             |\n",
    "| Bernoulli NB, Scikit-Learn Implementation                                  | 0.08             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn implementatiaons performed better than the MR implementation. The main difference between the two is the feature selection process, as sklearn strips out all punctuations. It is likely that these stripped features are noisy and don't offer predictive power, making the sklearn models better overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
